{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora-Insincere-Questions-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUVIu7Szs34K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "needs_installations = False\n",
        "needs_data_preparation = False\n",
        "should_train_models = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3vPe-_j1ugy",
        "colab_type": "text"
      },
      "source": [
        "##Kaggle Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Lh2dDfusli",
        "colab_type": "text"
      },
      "source": [
        "Upload kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRJKSBfMlYwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_installations:\n",
        "  from google.colab import files\n",
        "  files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nedILXEXouD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_installations:\n",
        "  !ls -lha kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtkAZZg1ktQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_installations:\n",
        "  !pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro3R3Ekhl828",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_installations:\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7acoN3VlBe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_installations:\n",
        "  !kaggle competitions download -c quora-insincere-questions-classification -p /content/drive/My\\ Drive/Colab\\ Notebooks/Research/Quora/zips/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm47_7qC13wR",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtBt19CfsKHP",
        "colab_type": "code",
        "outputId": "517843ec-de0a-4615-969a-26b19dffe2d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Basic Stuff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time, ctime\n",
        "import random\n",
        "\n",
        "# Basic Machine Learning Stuff\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# NLP Stuff\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Deep Learning Stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Visualization Stuff\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "\n",
        "# Drive Stuff\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import gc\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qU0Az80mW94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/drive/My Drive/Colab Notebooks/Research/Quora/'\n",
        "zips_path = 'zips/'\n",
        "data_path = 'data/'\n",
        "obj_path = 'obj/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raWEiB5Z189t",
        "colab_type": "text"
      },
      "source": [
        "#Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOH6-U4U2Equ",
        "colab_type": "text"
      },
      "source": [
        "##Prepare Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VD6co3rPNQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_obj(obj, name ):\n",
        "    with open(root_path + obj_path + name + '.pkl', 'wb+') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_obj(name ):\n",
        "  if os.path.isfile(root_path + obj_path + name + '.pkl'):\n",
        "    with open(root_path + obj_path + name + '.pkl', 'rb') as f:\n",
        "          return pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDJtDzwu1__r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_data_preparation:\n",
        "  root_dir = os.listdir(root_path)\n",
        "  zips_dir = os.listdir(root_path+zips_path)\n",
        "  print(zips_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z0vaJpi2b9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_data_preparation:\n",
        "  for zip_file_name in zips_dir:\n",
        "    with zipfile.ZipFile(root_path+zips_path+zip_file_name, 'r') as zip_ref:\n",
        "      print('Extracting: '+root_path+zips_path+zip_file_name)\n",
        "      zip_ref.extractall(root_path+data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd5-WbcN3Ubv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if needs_data_preparation:\n",
        "  data_dir = os.listdir(root_path+data_path)\n",
        "  print(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLPDN5PADV-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(root_path+data_path+'test.csv') \n",
        "sample_submission = pd.read_csv(root_path+data_path+'sample_submission.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3in4DJYUGmZ3",
        "colab_type": "text"
      },
      "source": [
        "###1. qid - unique question identifier\n",
        "###2. question_text - Quora question text\n",
        "###3. target - a question labeled \"insincere\" has a value of 1, otherwise 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ddoFI0iPAp",
        "colab_type": "code",
        "outputId": "5d211503-5ac2-4266-b672-7437da9e6e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "source": [
        "if needs_data_preparation:\n",
        "  train_data = pd.read_csv(root_path+data_path+'train.csv') \n",
        "  train_data['question_length'] = train_data.apply(lambda x: len(word_tokenize(x['question_text'])),axis=1)\n",
        "  train_data.to_csv(root_path+data_path+'train_data_with_length.csv')\n",
        "else:\n",
        "  train_data = pd.read_csv(root_path+data_path+'train_data_with_length.csv',index_col=0) \n",
        "\n",
        "m = np.max(train_data['question_length'])\n",
        "max_sentence = train_data.iloc[train_data['question_length'].idxmax()]['question_text']\n",
        "avg = np.mean(train_data['question_length'])\n",
        "print(\"Longesst Sentence Length: \"+str(m))\n",
        "print(\"Average Sentence Length: \"+str(avg))\n",
        "print(\"Longesst Sentence: \"+str(max_sentence))\n",
        "train_data['question_length'].hist(bins=128)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Longesst Sentence Length: 412\n",
            "Average Sentence Length: 14.44675688794768\n",
            "Longesst Sentence: What is [math]\\frac{\\int_{1x^5}^{3x^{-5}} \\tan(\\tan({\\boxed{\\int_{1x^0}^{1x^2} \\sum_{\\varpi=1}^{\\infty} \\int_{2x^{-3}}^{2x^2} \\sum_{\\alpha=7}^{\\infty} \\underbrace{\\sqrt[2]{1x^5}}_{\\text{Gauss's Law of Theoretical Probability.}} d\\tau dx}}^{1x^0})) d\\mu}{\\int_{2x^{-3}}^{1x^5} \\cos(\\int_{2x^2}^{1x^{-3}} \\frac{\\sqrt[2]{\\overbrace{\\underbrace{\\frac{3x^3+3x^5}{\\sqrt[3]{2x^{-3}}}}_{\\text{Gauss's Law of Theoretical Probability.}} \\times \\overbrace{\\tan(2x^0)}^{\\text{Gauss's Law of Theoretical Probability.}}-\\sum_{4=7}^{\\infty} \\boxed{3x^{-5}}}^{\\text{Inverse Function.}}}}{{\\boxed{\\int_{2x^2}^{2x^4} 3x^1 d9} \\div \\sum_{6=6}^{\\infty} \\sqrt[3]{2x^2}+\\sqrt[4]{\\sin(2x^0+3x^0)}}^{2x^{-4}}+\\boxed{\\frac{\\vec{\\boxed{\\sum_{\\gamma=10}^{\\infty} 1x^{-5}}}}{\\frac{\\sum_{\\iota=2}^{\\infty} 1x^{-5}-\\frac{3x^{-1}}{1x^{-4}}}{\\sin(\\tan(3x^{-2}))}}}} \\times \\boxed{\\sqrt[2]{{{{\\sqrt[5]{2x^5}}^{2x^{-1}}}^{2x^{-1}} \\div \\sum_{\\chi=6}^{\\infty} \\int_{1x^4}^{2x^{-4}} 3x^2 d\\vartheta+{2x^{-3}}^{2x^{-5}}}^{3x^{-4}}}} d\\mu) d\\iota}[/math]?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f76f12baa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEBCAYAAABbm4NtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n670AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQOLyPo2GYto",
        "colab_type": "code",
        "outputId": "09c71090-71e7-484a-c77b-ac6decfda714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "pd.set_option('max_colwidth', 128)\n",
        "train_data.head(1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>question_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... question_length\n",
              "0  00002165364db923c7e6  ...              14\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NToYINNUtld4",
        "colab_type": "code",
        "outputId": "c90080fc-c8a5-4cdb-d17a-07085d76a155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "train_data[train_data['question_length']<32]['question_length'].hist(bins=32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f76f79ac550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEBCAYAAABbm4NtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgpSlVm6Gb7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_data = train_data[train_data['target']==1]\n",
        "neg_data = train_data[train_data['target']==0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl5cXINYZGso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "0a4cc3a2-dba1-45bf-8f19-f988358dc433"
      },
      "source": [
        "neg_data.head(3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>question_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... question_length\n",
              "0  00002165364db923c7e6  ...              14\n",
              "1  000032939017120e6e44  ...              18\n",
              "2  0000412ca6e4628ce2cf  ...              12\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T1nZLtRZOy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "23c6314c-c2a1-4ac9-b027-2ae1c74c58f0"
      },
      "source": [
        "pos_data.head(3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>question_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0000e91571b60c2fb487</td>\n",
              "      <td>Has the United States become the largest dictatorship in the world?</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>00013ceca3f624b09f42</td>\n",
              "      <td>Which babies are more sweeter to their parents? Dark skin babies or light skin babies?</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0004a7fcb2bf73076489</td>\n",
              "      <td>If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      qid  ... question_length\n",
              "22   0000e91571b60c2fb487  ...              12\n",
              "30   00013ceca3f624b09f42  ...              17\n",
              "110  0004a7fcb2bf73076489  ...              17\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uwU9oiBJZm5",
        "colab_type": "code",
        "outputId": "55fe8484-7d97-4ba6-ef49-c39a538123a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"There are total of \"+str(train_data.size)+\" samples\")\n",
        "print(\"There are \"+str(pos_data.size)+\" positive samples (insincere)\")\n",
        "print(\"There are \"+str(neg_data.size)+\" negative samples (sincere)\")\n",
        "print(\"Ratio is: %.3f\" % (pos_data.size/neg_data.size))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are total of 5224488 samples\n",
            "There are 323240 positive samples (insincere)\n",
            "There are 4901248 negative samples (sincere)\n",
            "Ratio is: 0.066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNYHZ2JFHzsU",
        "colab_type": "code",
        "outputId": "14382b01-347c-4493-b18e-0ba99858d72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "train_data_balanced = pd.concat([resample(neg_data,replace = False,n_samples = len(pos_data)), pos_data])\n",
        "print(\"There are total of \"+str(train_data_balanced.shape)+\" samples\")\n",
        "train_data_balanced.head(3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are total of (161620, 4) samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>question_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>321222</th>\n",
              "      <td>3ef4fc9c0ff6b72f949b</td>\n",
              "      <td>How can one find peace in this hullabaloo of the world?</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167120</th>\n",
              "      <td>20a6443fa129ab48fdfb</td>\n",
              "      <td>How many student called for counselling in BHU for social science?</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253878</th>\n",
              "      <td>31afe34074608380a609</td>\n",
              "      <td>What are the importance of trees in human life?</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid  ... question_length\n",
              "321222  3ef4fc9c0ff6b72f949b  ...              12\n",
              "167120  20a6443fa129ab48fdfb  ...              12\n",
              "253878  31afe34074608380a609  ...              10\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfllsaBtQcbw",
        "colab_type": "text"
      },
      "source": [
        "###Resample Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNXPKq1Z3dKU",
        "colab_type": "code",
        "outputId": "4fb346e4-4cdd-43c8-d005-12f8e712ab62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "X,y = train_data_balanced.iloc[:,:2],train_data_balanced.iloc[:,2]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "number_of_samples = 50000\n",
        "updated_train_data_resampled = pd.concat([X_train, y_train],axis=1)\n",
        "train_data_balanced_resampled = resample(updated_train_data_resampled,replace = False,n_samples = number_of_samples)\n",
        "X_train_resampled, y_train_resampled = train_data_balanced_resampled.iloc[:,:2],train_data_balanced_resampled.iloc[:,2]\n",
        "chosen_question_length = 32\n",
        "word_vector_size = 300\n",
        "X_train_resampled.head(1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>499569</th>\n",
              "      <td>61cdf66a268622a197e0</td>\n",
              "      <td>Is Matt Damon's IQ actually 160?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid                     question_text\n",
              "499569  61cdf66a268622a197e0  Is Matt Damon's IQ actually 160?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUmdyeTOmniZ",
        "colab_type": "text"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jecYUN7p7Vgx",
        "colab_type": "text"
      },
      "source": [
        "###Challenges:\n",
        "1. Sentences are in different lengths\n",
        "2. Sequence order does matter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuR0ck8ySPby",
        "colab_type": "code",
        "outputId": "4f18f02e-794e-4cc7-b03b-25184e080be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data_dir = os.listdir(root_path+data_path)\n",
        "data_dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.csv',\n",
              " 'GoogleNews-vectors-negative300',\n",
              " 'glove.840B.300d',\n",
              " 'paragram_300_sl999',\n",
              " 'wiki-news-300d-1M',\n",
              " 'sample_submission.csv',\n",
              " 'test.csv',\n",
              " 'gensim_glove_vectors.txt',\n",
              " 'train_data_with_length.csv',\n",
              " 'paragram_glove_vectors.txt',\n",
              " 'gensim_paragram_vectors.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxD6W-LSdCox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QIQModel:\n",
        "  def run_on_all(self,X_train,y_train,X_test,y_test):\n",
        "    results = []\n",
        "    results.append(self.run_on_model(X_train,y_train,X_test,y_test,self.get_glove_embeddings()))\n",
        "    results.append(self.run_on_model(X_train,y_train,X_test,y_test,self.get_google_news_embeddings()))\n",
        "    results.append(self.run_on_model(X_train,y_train,X_test,y_test,self.get_wiki_news_embeddings()))\n",
        "    return results\n",
        "\n",
        "  def run_on_model(self,X_train,y_train,X_test,y_test,embeddings):\n",
        "    X_train,y_train,X_test,y_test = self.prepare_data(X_train,y_train,X_test,y_test,embeddings)\n",
        "    result = self.run(X_train,y_train,X_test,y_test)\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "  def run(self,X_train,y_train,X_test,y_test):\n",
        "    return 0.0\n",
        "\n",
        "  def prepare_data(self,X_train,y_train,X_test,y_test,embeddings):\n",
        "    chosen_question_length = 32\n",
        "    word_vector_size = 300\n",
        "\n",
        "    X_train_vectorized = self.reduce_dim_from_3_to_2(self.vectorize(X_train,chosen_question_length,word_vector_size,embeddings))\n",
        "    X_test_vectorized = self.reduce_dim_from_3_to_2(self.vectorize(X_test,chosen_question_length,word_vector_size,embeddings))\n",
        "\n",
        "    return X_train_vectorized,y_train,X_test_vectorized,y_test\n",
        "\n",
        "  def reduce_dim_from_3_to_2(self,X):\n",
        "    nsamples, nx, ny = X.shape\n",
        "    return X.reshape((nsamples,nx*ny))\n",
        "\n",
        "  def vectorize(self,X,chosen_question_length,word_vector_size,embeddings):\n",
        "    X_vectorized = np.empty((X.shape[0],chosen_question_length,word_vector_size))\n",
        "    for i in range(X.shape[0]):\n",
        "      current_sentence = word_tokenize(X.iloc[i]['question_text'])\n",
        "      for j in range(chosen_question_length):\n",
        "        if j<len(current_sentence) and current_sentence[j] in embeddings:\n",
        "          X_vectorized[i,j] = embeddings[current_sentence[j]]\n",
        "        else:\n",
        "          X_vectorized[i,j] = np.zeros((300,))\n",
        "      if i % 10000 ==0:\n",
        "        print(i,end =\"-\")\n",
        "    return X_vectorized  \n",
        "\n",
        "  def get_glove_embeddings(self):\n",
        "    if needs_data_preparation:\n",
        "      glove2word2vec(glove_input_file=root_path+data_path+'glove.840B.300d/glove.840B.300d.txt', word2vec_output_file=root_path+data_path+\"gensim_glove_vectors.txt\")    \n",
        "    return KeyedVectors.load_word2vec_format(root_path+data_path+\"gensim_glove_vectors.txt\", binary=False)\n",
        "  def get_google_news_embeddings(self):\n",
        "    return KeyedVectors.load_word2vec_format(root_path+data_path+'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "  # TODO: fix this one\n",
        "  def get_paragram_embeddings(self):\n",
        "    if needs_data_preparation:\n",
        "      glove2word2vec(glove_input_file=root_path+data_path+'paragram_300_sl999/paragram_300_sl999.txt', word2vec_output_file=root_path+data_path+\"gensim_paragram_vectors.txt\")\n",
        "    paragram_model = KeyedVectors.load_word2vec_format(root_path+data_path+'paragram_300_sl999/paragram_300_sl999.txt', binary=False)\n",
        "    return paragram_model\n",
        "  def get_wiki_news_embeddings(self):\n",
        "    return KeyedVectors.load_word2vec_format(root_path+data_path+'wiki-news-300d-1M/wiki-news-300d-1M.vec', binary=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUeEOMjaPSPK",
        "colab_type": "text"
      },
      "source": [
        "###Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMSu3iTsf2sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# m = QIQModel()\n",
        "# embed = m.get_wiki_news_embeddings()\n",
        "# print(embed['Hello'].shape)\n",
        "# del m\n",
        "# del embed\n",
        "# gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwsWVR-2XfIw",
        "colab_type": "code",
        "outputId": "c3cfd844-6133-44a9-cfb0-307e94447535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_resampled.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6ZHxwvTpOse",
        "colab_type": "text"
      },
      "source": [
        "##Baseline Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozmbUvdXpTue",
        "colab_type": "text"
      },
      "source": [
        "###Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-UbQZjkIyq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LRModel(QIQModel):\n",
        "  def run(self,X_train,y_train,X_test,y_test):\n",
        "    clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
        "    print(clf)\n",
        "    return clf.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afW9jxEGR3wb",
        "colab_type": "code",
        "outputId": "4862181f-faee-4cd0-bc26-49005c6465f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "lr = LRModel()\n",
        "results = lr.run_on_all(X_train_resampled, y_train_resampled, X_test, y_test)\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0-10000-20000-30000-40000-0-10000-20000-30000-"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "0.8457492884543992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0-10000-20000-30000-40000-0-10000-20000-30000-"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "0.8410778369013736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0-10000-20000-30000-40000-0-10000-20000-30000-"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "0.8527409974013117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8457492884543992, 0.8410778369013736, 0.8527409974013117]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W4LNK07pZjO",
        "colab_type": "text"
      },
      "source": [
        "###Naive Baise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIXuSGDuX23Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GNBModel(QIQModel):\n",
        "  def run(self,X_train,y_train,X_test,y_test):\n",
        "    gnb = GaussianNB().fit(X_train, y_train)\n",
        "    print(gnb)\n",
        "    return gnb.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmZBD9D3l9xK",
        "colab_type": "code",
        "outputId": "403c9a20-376a-4c67-a339-2e5643b58b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "gnb = GNBModel()\n",
        "results = gnb.run_on_all(X_train_resampled, y_train_resampled, X_test, y_test)\n",
        "results"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0-10000-20000-30000-40000-0-10000-20000-30000-GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "0.6191993565152828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0-10000-20000-30000-40000-0-10000-20000-30000-GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "0.6204987006558594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0-10000-20000-30000-40000-0-10000-20000-30000-GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "0.6195396609330528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6191993565152828, 0.6204987006558594, 0.6195396609330528]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QTPTuFxYG93",
        "colab_type": "text"
      },
      "source": [
        "###XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWy9SuokYNwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XGBModel(QIQModel):\n",
        "  def run(self,X_train,y_train,X_test,y_test):\n",
        "    gbm = XGBClassifier()\n",
        "    print(gbm)\n",
        "    gbm.fit(X_train, y_train)\n",
        "    return gbm.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3EE6igvLcQh",
        "colab_type": "code",
        "outputId": "deac2b7e-a110-4149-9c15-d9258b050791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "xgb = XGBModel()\n",
        "results = xgb.run_on_all(X_train_resampled, y_train_resampled, X_test, y_test)\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0-10000-20000-30000-40000-0-10000-20000-30000-"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgcomhLuF5YS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(clf,sentnce):\n",
        "  X_vectorized = np.empty((1,chosen_question_length,word_vector_size))\n",
        "  current_sentence = word_tokenize(sentnce)\n",
        "  for j in range(chosen_question_length):\n",
        "    if j<len(current_sentence) and current_sentence[j] in glove_model:\n",
        "      X_vectorized[0,j] = glove_model[current_sentence[j]]\n",
        "    else:\n",
        "      X_vectorized[0,j] = np.zeros((300,))\n",
        "  return clf.predict(X_vectorized.reshape(1,chosen_question_length*word_vector_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd4MX2r0dgYb",
        "colab_type": "code",
        "outputId": "75f8d3ec-a11d-402c-ca96-1d1f04f92052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lets_have_fun = [\"What is wrong with fat ass?\",\"What is love?\",\"What is wrong with fat milk?\",\"Do Arabs eat humus?\",\"Do aliens exist?\"]\n",
        "\n",
        "for s in lets_have_fun:\n",
        "  result = predict(clf,s)\n",
        "  print(s+'\\t is '+ ('insincere' if predict(clf,s)[0] else 'sincere'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is wrong with fat ass?\t is insincere\n",
            "What is love?\t is sincere\n",
            "What is wrong with fat milk?\t is insincere\n",
            "Do Arabs eat humus?\t is insincere\n",
            "Do aliens exist?\t is sincere\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ-bV_v6dpUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zPDJ4glpnwt",
        "colab_type": "text"
      },
      "source": [
        "##Baseline Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzOa_1ZXprMm",
        "colab_type": "code",
        "outputId": "f7a099e6-1ace-468e-a0eb-a6f0cd7ce7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "results = np.array([[0.8457492884543992, 0.8410778369013736, 0.8527409974013117],[0.6191993565152828, 0.6204987006558594, 0.6195396609330528]]).T\n",
        "summery_df = pd.DataFrame(results, columns=['Logistic Regression', 'Gaussian Naive Bayes'])\n",
        "summery_df.index.name = 'Embeddings'\n",
        "summery_df.index = ['Glove','Google News','Wiki News']\n",
        "summery_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Gaussian Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Glove</th>\n",
              "      <td>0.845749</td>\n",
              "      <td>0.619199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Google News</th>\n",
              "      <td>0.841078</td>\n",
              "      <td>0.620499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wiki News</th>\n",
              "      <td>0.852741</td>\n",
              "      <td>0.619540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Logistic Regression  Gaussian Naive Bayes\n",
              "Glove                   0.845749              0.619199\n",
              "Google News             0.841078              0.620499\n",
              "Wiki News               0.852741              0.619540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYMVsTrczhUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuoraDataset(Dataset):\n",
        "  def __init__(self,X_train,y_train):\n",
        "    print(\"Init QuoraDataset at: \"+str(ctime()))\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.embeddings = self.get_wiki_news_embeddings()\n",
        "    print(\"Finish init QuoraDataset at: \"+str(ctime()))\n",
        "\n",
        "  def get_glove_embeddings(self):\n",
        "    return KeyedVectors.load_word2vec_format(root_path+data_path+\"gensim_glove_vectors.txt\", binary=False)\n",
        "\n",
        "  def get_wiki_news_embeddings(self):\n",
        "    return KeyedVectors.load_word2vec_format(root_path+data_path+'wiki-news-300d-1M/wiki-news-300d-1M.vec', binary=False)\n",
        "   \n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    X = self.prepare_data(self.X_train.iloc[idx:idx+1,:])\n",
        "    return (X,self.y_train.iloc[idx])\n",
        "\n",
        "  def prepare_data(self,X_train):\n",
        "    chosen_question_length = 32\n",
        "    word_vector_size = 300\n",
        "\n",
        "    X_train_vectorized = self.vectorize(X_train,chosen_question_length,word_vector_size)\n",
        "\n",
        "    return X_train_vectorized\n",
        "\n",
        "  def vectorize(self,X,chosen_question_length,word_vector_size):\n",
        "    X_vectorized = np.empty((X.shape[0],chosen_question_length,word_vector_size))\n",
        "    for i in range(X.shape[0]):\n",
        "      current_sentence = word_tokenize(X.iloc[i]['question_text'])\n",
        "      for j in range(chosen_question_length):\n",
        "        if j<len(current_sentence) and current_sentence[j] in self.embeddings:\n",
        "          X_vectorized[i,j] = self.embeddings[current_sentence[j]]\n",
        "        else:\n",
        "          X_vectorized[i,j] = np.zeros((300,))\n",
        "    return X_vectorized  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVFUbYtxjdkU",
        "colab_type": "code",
        "outputId": "8e4b0cea-2454-40ca-d896-ad054b235609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "X_train.iloc[0:1,:]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>264449</th>\n",
              "      <td>33bf9a08bc466a8439f2</td>\n",
              "      <td>Why do Christians in India hate Brahmins so much?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid                                      question_text\n",
              "264449  33bf9a08bc466a8439f2  Why do Christians in India hate Brahmins so much?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oGvFZ7Q0sBp",
        "colab_type": "code",
        "outputId": "c70d11a5-5a95-43a8-aa5a-571527bd334f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "quora_train_set = QuoraDataset(X_train,y_train)\n",
        "quora_dataloader = DataLoader(quora_train_set, batch_size=50, shuffle=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init QuoraDataset at: Thu Sep 19 12:02:13 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish init QuoraDataset at: Thu Sep 19 12:07:00 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUgS5dCatBGF",
        "colab_type": "code",
        "outputId": "0857b780-7aad-4f5f-d647-17f0e5a8b341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "quora_train_set"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.QuoraDataset at 0x7f996355ee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4y0AEYozfTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class YKCNN(nn.Module):\n",
        "    def __init__(self, channels_number=1):\n",
        "      super(YKCNN, self).__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_channels=channels_number, out_channels=100, kernel_size=(5,300),stride=(1,1), padding=(2,0))\n",
        "      # self.conv1 = nn.Conv2d(in_channels=channels_number, out_channels=100, kernel_size=(7,300),stride=(1,1), padding=(3,0))\n",
        "      self.fc1 = nn.Linear(in_features = 600, out_features = 2)\n",
        "      # self.batch_norm = nn.BatchNorm1d(num_features=120)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        x = F.max_pool2d(torch.tanh(self.conv1(x)), (5,300))\n",
        "        # x = F.max_pool2d(F.tanh(self.conv2(x)), (5,300))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        # print(\"I'm inlove with the shape of x: \"+str(x.shape)+\" after flattening\")\n",
        "        x = F.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        # print(\"I'm inlove with the shape of x: \"+str(x.shape)+\" after fc1\")\n",
        "        # x = self.batch_norm(x)\n",
        "        x = F.log_softmax(x,dim=0)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYf2iIvBYgnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27e689f2-ce5f-4e6d-8cf9-71fd803ffbdd"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpWBK4qGzH2r",
        "colab_type": "code",
        "outputId": "19da7249-a0a3-4a91-d860-c5c5ce806a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "net = YKCNN().cuda()     # -- For GPU\n",
        "print(net)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "YKCNN(\n",
            "  (conv1): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1), padding=(2, 0))\n",
            "  (fc1): Linear(in_features=600, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coK-nRMxzKx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ozySwmzPZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training loop\n",
        "def train(net, trainloader, epochs=30):\n",
        "  loss_array = []\n",
        "  for epoch in range(epochs):  \n",
        "    torch.save(net.state_dict(), root_path+data_path+'model')\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        # print(\"Data Loading starts at: \"+str(ctime()))\n",
        "        # print(data[0].shape)\n",
        "        inputs, labels = data\n",
        "        # print(\"Finished fetching \"+str(len(inputs))+\" items at: \"+str(ctime()))\n",
        "\n",
        "        inputs = inputs.cuda() # -- For GPU\n",
        "        labels = labels.cuda() # -- For GPU\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # print(inputs.shape)\n",
        "        # print(\"Forward starts at: \"+str(ctime()))\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # print(\"Loss starts at: \"+str(ctime()))\n",
        "        loss = criterion(outputs, labels)\n",
        "        # print(\"Backward starts at: \"+str(ctime()))\n",
        "        loss.backward()\n",
        "        # print(\"Optimizer starts at: \"+str(ctime()))\n",
        "        optimizer.step()\n",
        "        # print(\"Optimizer ends at: \"+str(ctime()))\n",
        "\n",
        "        # print statistics\n",
        "        # print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "        if (i % 200 == 0) and (i > 0):    \n",
        "            print('%s: [%d, %5d] loss: %.3f' %\n",
        "                  (ctime().split()[3], epoch, i, running_loss / 200))\n",
        "\n",
        "            loss_array.append(running_loss / 200)\n",
        "            running_loss = 0.0\n",
        "        # print(\"Step ends at: \"+str(ctime()+\"\\n\"))\n",
        "             \n",
        "  print('Finished Training')\n",
        "  return loss_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpbD8abzTcxp",
        "colab_type": "code",
        "outputId": "69b55a7e-cd3f-4963-ffb3-1ee346fa4305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "original_loss_array = train(net, quora_dataloader)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12:11:29: [0,   200] loss: 0.310\n",
            "12:11:38: [0,   400] loss: 0.310\n",
            "12:11:47: [0,   600] loss: 0.305\n",
            "12:11:56: [0,   800] loss: 0.318\n",
            "12:12:05: [0,  1000] loss: 0.313\n",
            "12:12:14: [0,  1200] loss: 0.297\n",
            "12:12:23: [0,  1400] loss: 0.302\n",
            "12:12:33: [0,  1600] loss: 0.296\n",
            "12:12:42: [0,  1800] loss: 0.299\n",
            "12:12:51: [0,  2000] loss: 0.305\n",
            "12:13:00: [0,  2200] loss: 0.294\n",
            "12:13:09: [0,  2400] loss: 0.300\n",
            "12:13:27: [1,   200] loss: 0.270\n",
            "12:13:36: [1,   400] loss: 0.276\n",
            "12:13:45: [1,   600] loss: 0.286\n",
            "12:13:54: [1,   800] loss: 0.287\n",
            "12:14:04: [1,  1000] loss: 0.277\n",
            "12:14:13: [1,  1200] loss: 0.291\n",
            "12:14:23: [1,  1400] loss: 0.279\n",
            "12:14:32: [1,  1600] loss: 0.298\n",
            "12:14:41: [1,  1800] loss: 0.278\n",
            "12:14:50: [1,  2000] loss: 0.273\n",
            "12:14:59: [1,  2200] loss: 0.282\n",
            "12:15:08: [1,  2400] loss: 0.284\n",
            "12:15:26: [2,   200] loss: 0.258\n",
            "12:15:35: [2,   400] loss: 0.264\n",
            "12:15:44: [2,   600] loss: 0.281\n",
            "12:15:53: [2,   800] loss: 0.262\n",
            "12:16:03: [2,  1000] loss: 0.269\n",
            "12:16:12: [2,  1200] loss: 0.268\n",
            "12:16:21: [2,  1400] loss: 0.260\n",
            "12:16:31: [2,  1600] loss: 0.263\n",
            "12:16:40: [2,  1800] loss: 0.269\n",
            "12:16:50: [2,  2000] loss: 0.261\n",
            "12:16:59: [2,  2200] loss: 0.274\n",
            "12:17:09: [2,  2400] loss: 0.280\n",
            "12:17:27: [3,   200] loss: 0.240\n",
            "12:17:36: [3,   400] loss: 0.254\n",
            "12:17:46: [3,   600] loss: 0.254\n",
            "12:17:55: [3,   800] loss: 0.256\n",
            "12:18:05: [3,  1000] loss: 0.247\n",
            "12:18:14: [3,  1200] loss: 0.254\n",
            "12:18:23: [3,  1400] loss: 0.260\n",
            "12:18:33: [3,  1600] loss: 0.261\n",
            "12:18:42: [3,  1800] loss: 0.254\n",
            "12:18:52: [3,  2000] loss: 0.255\n",
            "12:19:01: [3,  2200] loss: 0.249\n",
            "12:19:10: [3,  2400] loss: 0.268\n",
            "12:19:29: [4,   200] loss: 0.233\n",
            "12:19:38: [4,   400] loss: 0.240\n",
            "12:19:47: [4,   600] loss: 0.225\n",
            "12:19:57: [4,   800] loss: 0.246\n",
            "12:20:06: [4,  1000] loss: 0.251\n",
            "12:20:16: [4,  1200] loss: 0.250\n",
            "12:20:25: [4,  1400] loss: 0.242\n",
            "12:20:34: [4,  1600] loss: 0.237\n",
            "12:20:44: [4,  1800] loss: 0.240\n",
            "12:20:53: [4,  2000] loss: 0.240\n",
            "12:21:03: [4,  2200] loss: 0.246\n",
            "12:21:12: [4,  2400] loss: 0.243\n",
            "12:21:30: [5,   200] loss: 0.223\n",
            "12:21:40: [5,   400] loss: 0.225\n",
            "12:21:49: [5,   600] loss: 0.235\n",
            "12:21:58: [5,   800] loss: 0.228\n",
            "12:22:08: [5,  1000] loss: 0.231\n",
            "12:22:17: [5,  1200] loss: 0.228\n",
            "12:22:26: [5,  1400] loss: 0.237\n",
            "12:22:36: [5,  1600] loss: 0.228\n",
            "12:22:45: [5,  1800] loss: 0.231\n",
            "12:22:55: [5,  2000] loss: 0.234\n",
            "12:23:04: [5,  2200] loss: 0.249\n",
            "12:23:13: [5,  2400] loss: 0.238\n",
            "12:23:31: [6,   200] loss: 0.219\n",
            "12:23:41: [6,   400] loss: 0.209\n",
            "12:23:50: [6,   600] loss: 0.215\n",
            "12:24:00: [6,   800] loss: 0.214\n",
            "12:24:09: [6,  1000] loss: 0.218\n",
            "12:24:18: [6,  1200] loss: 0.221\n",
            "12:24:28: [6,  1400] loss: 0.217\n",
            "12:24:37: [6,  1600] loss: 0.225\n",
            "12:24:47: [6,  1800] loss: 0.237\n",
            "12:24:56: [6,  2000] loss: 0.223\n",
            "12:25:06: [6,  2200] loss: 0.234\n",
            "12:25:15: [6,  2400] loss: 0.225\n",
            "12:25:33: [7,   200] loss: 0.215\n",
            "12:25:43: [7,   400] loss: 0.199\n",
            "12:25:52: [7,   600] loss: 0.209\n",
            "12:26:02: [7,   800] loss: 0.206\n",
            "12:26:11: [7,  1000] loss: 0.214\n",
            "12:26:20: [7,  1200] loss: 0.210\n",
            "12:26:30: [7,  1400] loss: 0.220\n",
            "12:26:39: [7,  1600] loss: 0.213\n",
            "12:26:48: [7,  1800] loss: 0.226\n",
            "12:26:58: [7,  2000] loss: 0.228\n",
            "12:27:07: [7,  2200] loss: 0.208\n",
            "12:27:17: [7,  2400] loss: 0.217\n",
            "12:27:35: [8,   200] loss: 0.199\n",
            "12:27:44: [8,   400] loss: 0.190\n",
            "12:27:54: [8,   600] loss: 0.202\n",
            "12:28:03: [8,   800] loss: 0.209\n",
            "12:28:13: [8,  1000] loss: 0.192\n",
            "12:28:22: [8,  1200] loss: 0.207\n",
            "12:28:32: [8,  1400] loss: 0.212\n",
            "12:28:41: [8,  1600] loss: 0.215\n",
            "12:28:51: [8,  1800] loss: 0.209\n",
            "12:29:00: [8,  2000] loss: 0.217\n",
            "12:29:09: [8,  2200] loss: 0.214\n",
            "12:29:19: [8,  2400] loss: 0.217\n",
            "12:29:37: [9,   200] loss: 0.180\n",
            "12:29:47: [9,   400] loss: 0.190\n",
            "12:29:56: [9,   600] loss: 0.188\n",
            "12:30:05: [9,   800] loss: 0.202\n",
            "12:30:15: [9,  1000] loss: 0.201\n",
            "12:30:24: [9,  1200] loss: 0.199\n",
            "12:30:34: [9,  1400] loss: 0.203\n",
            "12:30:43: [9,  1600] loss: 0.204\n",
            "12:30:53: [9,  1800] loss: 0.204\n",
            "12:31:02: [9,  2000] loss: 0.207\n",
            "12:31:12: [9,  2200] loss: 0.217\n",
            "12:31:21: [9,  2400] loss: 0.211\n",
            "12:31:39: [10,   200] loss: 0.191\n",
            "12:31:49: [10,   400] loss: 0.182\n",
            "12:31:58: [10,   600] loss: 0.189\n",
            "12:32:07: [10,   800] loss: 0.198\n",
            "12:32:17: [10,  1000] loss: 0.192\n",
            "12:32:26: [10,  1200] loss: 0.203\n",
            "12:32:36: [10,  1400] loss: 0.199\n",
            "12:32:45: [10,  1600] loss: 0.199\n",
            "12:32:55: [10,  1800] loss: 0.200\n",
            "12:33:04: [10,  2000] loss: 0.199\n",
            "12:33:13: [10,  2200] loss: 0.201\n",
            "12:33:23: [10,  2400] loss: 0.200\n",
            "12:33:41: [11,   200] loss: 0.179\n",
            "12:33:50: [11,   400] loss: 0.181\n",
            "12:34:00: [11,   600] loss: 0.187\n",
            "12:34:09: [11,   800] loss: 0.181\n",
            "12:34:18: [11,  1000] loss: 0.187\n",
            "12:34:28: [11,  1200] loss: 0.187\n",
            "12:34:37: [11,  1400] loss: 0.191\n",
            "12:34:47: [11,  1600] loss: 0.192\n",
            "12:34:56: [11,  1800] loss: 0.196\n",
            "12:35:06: [11,  2000] loss: 0.188\n",
            "12:35:15: [11,  2200] loss: 0.192\n",
            "12:35:25: [11,  2400] loss: 0.199\n",
            "12:35:43: [12,   200] loss: 0.175\n",
            "12:35:52: [12,   400] loss: 0.178\n",
            "12:36:02: [12,   600] loss: 0.172\n",
            "12:36:11: [12,   800] loss: 0.183\n",
            "12:36:21: [12,  1000] loss: 0.183\n",
            "12:36:30: [12,  1200] loss: 0.189\n",
            "12:36:39: [12,  1400] loss: 0.189\n",
            "12:36:49: [12,  1600] loss: 0.190\n",
            "12:36:58: [12,  1800] loss: 0.198\n",
            "12:37:08: [12,  2000] loss: 0.191\n",
            "12:37:17: [12,  2200] loss: 0.194\n",
            "12:37:26: [12,  2400] loss: 0.188\n",
            "12:37:44: [13,   200] loss: 0.169\n",
            "12:37:54: [13,   400] loss: 0.172\n",
            "12:38:03: [13,   600] loss: 0.174\n",
            "12:38:13: [13,   800] loss: 0.176\n",
            "12:38:22: [13,  1000] loss: 0.180\n",
            "12:38:32: [13,  1200] loss: 0.167\n",
            "12:38:41: [13,  1400] loss: 0.184\n",
            "12:38:51: [13,  1600] loss: 0.195\n",
            "12:39:00: [13,  1800] loss: 0.183\n",
            "12:39:09: [13,  2000] loss: 0.188\n",
            "12:39:19: [13,  2200] loss: 0.194\n",
            "12:39:28: [13,  2400] loss: 0.189\n",
            "12:39:46: [14,   200] loss: 0.164\n",
            "12:39:56: [14,   400] loss: 0.165\n",
            "12:40:05: [14,   600] loss: 0.166\n",
            "12:40:15: [14,   800] loss: 0.178\n",
            "12:40:24: [14,  1000] loss: 0.178\n",
            "12:40:34: [14,  1200] loss: 0.170\n",
            "12:40:43: [14,  1400] loss: 0.172\n",
            "12:40:53: [14,  1600] loss: 0.191\n",
            "12:41:02: [14,  1800] loss: 0.181\n",
            "12:41:11: [14,  2000] loss: 0.186\n",
            "12:41:21: [14,  2200] loss: 0.186\n",
            "12:41:30: [14,  2400] loss: 0.188\n",
            "12:41:49: [15,   200] loss: 0.165\n",
            "12:41:58: [15,   400] loss: 0.162\n",
            "12:42:07: [15,   600] loss: 0.154\n",
            "12:42:17: [15,   800] loss: 0.175\n",
            "12:42:26: [15,  1000] loss: 0.167\n",
            "12:42:36: [15,  1200] loss: 0.175\n",
            "12:42:45: [15,  1400] loss: 0.167\n",
            "12:42:54: [15,  1600] loss: 0.172\n",
            "12:43:04: [15,  1800] loss: 0.184\n",
            "12:43:13: [15,  2000] loss: 0.179\n",
            "12:43:23: [15,  2200] loss: 0.179\n",
            "12:43:32: [15,  2400] loss: 0.189\n",
            "12:43:50: [16,   200] loss: 0.158\n",
            "12:44:00: [16,   400] loss: 0.152\n",
            "12:44:09: [16,   600] loss: 0.165\n",
            "12:44:18: [16,   800] loss: 0.165\n",
            "12:44:28: [16,  1000] loss: 0.173\n",
            "12:44:37: [16,  1200] loss: 0.172\n",
            "12:44:47: [16,  1400] loss: 0.172\n",
            "12:44:56: [16,  1600] loss: 0.175\n",
            "12:45:06: [16,  1800] loss: 0.175\n",
            "12:45:15: [16,  2000] loss: 0.180\n",
            "12:45:24: [16,  2200] loss: 0.168\n",
            "12:45:34: [16,  2400] loss: 0.177\n",
            "12:45:52: [17,   200] loss: 0.157\n",
            "12:46:01: [17,   400] loss: 0.153\n",
            "12:46:10: [17,   600] loss: 0.163\n",
            "12:46:20: [17,   800] loss: 0.163\n",
            "12:46:29: [17,  1000] loss: 0.166\n",
            "12:46:39: [17,  1200] loss: 0.165\n",
            "12:46:48: [17,  1400] loss: 0.172\n",
            "12:46:57: [17,  1600] loss: 0.168\n",
            "12:47:07: [17,  1800] loss: 0.172\n",
            "12:47:16: [17,  2000] loss: 0.175\n",
            "12:47:26: [17,  2200] loss: 0.171\n",
            "12:47:35: [17,  2400] loss: 0.180\n",
            "12:47:53: [18,   200] loss: 0.144\n",
            "12:48:03: [18,   400] loss: 0.153\n",
            "12:48:12: [18,   600] loss: 0.157\n",
            "12:48:21: [18,   800] loss: 0.155\n",
            "12:48:31: [18,  1000] loss: 0.163\n",
            "12:48:40: [18,  1200] loss: 0.164\n",
            "12:48:50: [18,  1400] loss: 0.165\n",
            "12:48:59: [18,  1600] loss: 0.170\n",
            "12:49:09: [18,  1800] loss: 0.177\n",
            "12:49:18: [18,  2000] loss: 0.171\n",
            "12:49:27: [18,  2200] loss: 0.175\n",
            "12:49:37: [18,  2400] loss: 0.176\n",
            "12:49:55: [19,   200] loss: 0.141\n",
            "12:50:04: [19,   400] loss: 0.148\n",
            "12:50:14: [19,   600] loss: 0.152\n",
            "12:50:23: [19,   800] loss: 0.161\n",
            "12:50:33: [19,  1000] loss: 0.155\n",
            "12:50:42: [19,  1200] loss: 0.153\n",
            "12:50:52: [19,  1400] loss: 0.164\n",
            "12:51:01: [19,  1600] loss: 0.173\n",
            "12:51:11: [19,  1800] loss: 0.172\n",
            "12:51:20: [19,  2000] loss: 0.176\n",
            "12:51:30: [19,  2200] loss: 0.169\n",
            "12:51:39: [19,  2400] loss: 0.171\n",
            "12:51:57: [20,   200] loss: 0.154\n",
            "12:52:07: [20,   400] loss: 0.149\n",
            "12:52:16: [20,   600] loss: 0.146\n",
            "12:52:26: [20,   800] loss: 0.163\n",
            "12:52:35: [20,  1000] loss: 0.154\n",
            "12:52:44: [20,  1200] loss: 0.153\n",
            "12:52:54: [20,  1400] loss: 0.163\n",
            "12:53:03: [20,  1600] loss: 0.158\n",
            "12:53:12: [20,  1800] loss: 0.161\n",
            "12:53:22: [20,  2000] loss: 0.153\n",
            "12:53:31: [20,  2200] loss: 0.165\n",
            "12:53:40: [20,  2400] loss: 0.172\n",
            "12:53:59: [21,   200] loss: 0.144\n",
            "12:54:08: [21,   400] loss: 0.148\n",
            "12:54:18: [21,   600] loss: 0.154\n",
            "12:54:27: [21,   800] loss: 0.160\n",
            "12:54:37: [21,  1000] loss: 0.162\n",
            "12:54:46: [21,  1200] loss: 0.162\n",
            "12:54:55: [21,  1400] loss: 0.162\n",
            "12:55:05: [21,  1600] loss: 0.162\n",
            "12:55:14: [21,  1800] loss: 0.152\n",
            "12:55:23: [21,  2000] loss: 0.161\n",
            "12:55:33: [21,  2200] loss: 0.158\n",
            "12:55:42: [21,  2400] loss: 0.168\n",
            "12:56:00: [22,   200] loss: 0.155\n",
            "12:56:10: [22,   400] loss: 0.146\n",
            "12:56:19: [22,   600] loss: 0.138\n",
            "12:56:28: [22,   800] loss: 0.147\n",
            "12:56:38: [22,  1000] loss: 0.158\n",
            "12:56:47: [22,  1200] loss: 0.152\n",
            "12:56:56: [22,  1400] loss: 0.156\n",
            "12:57:06: [22,  1600] loss: 0.158\n",
            "12:57:15: [22,  1800] loss: 0.153\n",
            "12:57:25: [22,  2000] loss: 0.160\n",
            "12:57:34: [22,  2200] loss: 0.159\n",
            "12:57:43: [22,  2400] loss: 0.163\n",
            "12:58:02: [23,   200] loss: 0.144\n",
            "12:58:11: [23,   400] loss: 0.141\n",
            "12:58:21: [23,   600] loss: 0.144\n",
            "12:58:30: [23,   800] loss: 0.146\n",
            "12:58:39: [23,  1000] loss: 0.159\n",
            "12:58:49: [23,  1200] loss: 0.155\n",
            "12:58:58: [23,  1400] loss: 0.155\n",
            "12:59:07: [23,  1600] loss: 0.150\n",
            "12:59:17: [23,  1800] loss: 0.145\n",
            "12:59:26: [23,  2000] loss: 0.155\n",
            "12:59:36: [23,  2200] loss: 0.149\n",
            "12:59:45: [23,  2400] loss: 0.165\n",
            "13:00:03: [24,   200] loss: 0.145\n",
            "13:00:13: [24,   400] loss: 0.143\n",
            "13:00:22: [24,   600] loss: 0.137\n",
            "13:00:31: [24,   800] loss: 0.142\n",
            "13:00:41: [24,  1000] loss: 0.147\n",
            "13:00:50: [24,  1200] loss: 0.153\n",
            "13:01:00: [24,  1400] loss: 0.149\n",
            "13:01:09: [24,  1600] loss: 0.150\n",
            "13:01:19: [24,  1800] loss: 0.157\n",
            "13:01:28: [24,  2000] loss: 0.162\n",
            "13:01:37: [24,  2200] loss: 0.167\n",
            "13:01:47: [24,  2400] loss: 0.163\n",
            "13:02:05: [25,   200] loss: 0.152\n",
            "13:02:14: [25,   400] loss: 0.139\n",
            "13:02:24: [25,   600] loss: 0.143\n",
            "13:02:33: [25,   800] loss: 0.142\n",
            "13:02:42: [25,  1000] loss: 0.148\n",
            "13:02:51: [25,  1200] loss: 0.148\n",
            "13:03:01: [25,  1400] loss: 0.155\n",
            "13:03:10: [25,  1600] loss: 0.150\n",
            "13:03:20: [25,  1800] loss: 0.148\n",
            "13:03:29: [25,  2000] loss: 0.154\n",
            "13:03:38: [25,  2200] loss: 0.151\n",
            "13:03:48: [25,  2400] loss: 0.154\n",
            "13:04:06: [26,   200] loss: 0.141\n",
            "13:04:15: [26,   400] loss: 0.144\n",
            "13:04:24: [26,   600] loss: 0.145\n",
            "13:04:34: [26,   800] loss: 0.155\n",
            "13:04:43: [26,  1000] loss: 0.152\n",
            "13:04:53: [26,  1200] loss: 0.141\n",
            "13:05:02: [26,  1400] loss: 0.145\n",
            "13:05:12: [26,  1600] loss: 0.151\n",
            "13:05:21: [26,  1800] loss: 0.147\n",
            "13:05:30: [26,  2000] loss: 0.152\n",
            "13:05:40: [26,  2200] loss: 0.150\n",
            "13:05:49: [26,  2400] loss: 0.156\n",
            "13:06:07: [27,   200] loss: 0.133\n",
            "13:06:17: [27,   400] loss: 0.135\n",
            "13:06:26: [27,   600] loss: 0.140\n",
            "13:06:35: [27,   800] loss: 0.142\n",
            "13:06:45: [27,  1000] loss: 0.149\n",
            "13:06:54: [27,  1200] loss: 0.147\n",
            "13:07:04: [27,  1400] loss: 0.149\n",
            "13:07:13: [27,  1600] loss: 0.148\n",
            "13:07:23: [27,  1800] loss: 0.159\n",
            "13:07:32: [27,  2000] loss: 0.142\n",
            "13:07:42: [27,  2200] loss: 0.144\n",
            "13:07:51: [27,  2400] loss: 0.151\n",
            "13:08:09: [28,   200] loss: 0.129\n",
            "13:08:19: [28,   400] loss: 0.145\n",
            "13:08:28: [28,   600] loss: 0.136\n",
            "13:08:38: [28,   800] loss: 0.134\n",
            "13:08:47: [28,  1000] loss: 0.147\n",
            "13:08:56: [28,  1200] loss: 0.140\n",
            "13:09:06: [28,  1400] loss: 0.152\n",
            "13:09:15: [28,  1600] loss: 0.142\n",
            "13:09:25: [28,  1800] loss: 0.141\n",
            "13:09:34: [28,  2000] loss: 0.159\n",
            "13:09:43: [28,  2200] loss: 0.148\n",
            "13:09:53: [28,  2400] loss: 0.154\n",
            "13:10:11: [29,   200] loss: 0.136\n",
            "13:10:20: [29,   400] loss: 0.130\n",
            "13:10:30: [29,   600] loss: 0.136\n",
            "13:10:39: [29,   800] loss: 0.134\n",
            "13:10:49: [29,  1000] loss: 0.137\n",
            "13:10:58: [29,  1200] loss: 0.144\n",
            "13:11:08: [29,  1400] loss: 0.141\n",
            "13:11:17: [29,  1600] loss: 0.134\n",
            "13:11:26: [29,  1800] loss: 0.146\n",
            "13:11:36: [29,  2000] loss: 0.147\n",
            "13:11:45: [29,  2200] loss: 0.148\n",
            "13:11:55: [29,  2400] loss: 0.158\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAZYMJgfsgzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save_obj(net, 'net_conv_5')\n",
        "net = load_obj('net_conv_5')\n",
        "# save_obj(net, 'net_conv_7')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDPji73TsU9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cff827b8-fdb4-45c3-c220-75b48e9692dc"
      },
      "source": [
        "net"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YKCNN(\n",
              "  (conv1): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1), padding=(2, 0))\n",
              "  (fc1): Linear(in_features=600, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BAkJzy3Cr0J",
        "colab_type": "code",
        "outputId": "bd037fe3-da4f-48fe-ebe0-ac5532347300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "del quora_train_set\n",
        "del quora_dataloader\n",
        "gc.collect()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-69a22933e462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mquora_train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mquora_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'quora_train_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjspDwK-Uwz8",
        "colab_type": "code",
        "outputId": "5485dc31-3be0-464d-a955-2dd001d9c256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "a = np.array(original_loss_array).reshape((len(original_loss_array),1))\n",
        "print(a.shape)\n",
        "b = np.array([float(i) for i in range(len(original_loss_array))]).reshape((len(original_loss_array),1))\n",
        "print(b.shape)\n",
        "\n",
        "data = pd.DataFrame(np.concatenate((a,b),axis=1), columns = [\"loss\",\"time\"])\n",
        "# data.head()\n",
        "ax = sns.lineplot(x=\"time\", y=\"loss\", data=data)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(360, 1)\n",
            "(360, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAESCAYAAAAmOQivAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvXtgFPW5///emb1mN5vrJtmEe5AQ\nIRSVYlFBKaVwamioHosH0XMOivVyylf0R03bc7jY+rPQllYscFq+AuVoq0UsHAOi4qVcFFFBbuEm\nJFxyz242ySZ7nZ3vH7MzO7s7uwmYLLvkef3jZuYzs88mOO99ns9zUfE8z4MgCIIgEgBzrQ0gCIIg\nBg4kOgRBEETCINEhCIIgEgaJDkEQBJEwSHQIgiCIhEGiQxAEQSQMEh2CIAgiYZDoEARBEAmDRIcg\nCIJIGCQ6BEEQRMIg0SEIgiAShjpRb1RTU4PKyko4HA5kZmZixYoVGDZsWNiarVu3YtOmTWAYBoFA\nAPfddx8eeughAMCaNWuwc+dOMAwDjUaDRYsWYfLkyQCAyspKfPzxx8jKygIAzJw5E48//niiPhpB\nEATRS1SJavj50EMP4d5770VFRQW2b9+OrVu3YvPmzWFrnE4njEYjVCoVnE4nZs2ahXXr1mH06NHY\nu3cvJkyYAIPBgFOnTmHevHnYt28f9Ho9KisrMXbsWMybNy8RH4UgCIK4ShLi6dhsNlRXV2Pjxo0A\ngPLycvziF7+A3W5Hdna2tM5kMkmv3W43fD4fVCoVAEheDQCUlJSA53k4HA4UFBT0iY1tbV0IBK5c\nf3NyTLDZnH1iQ3+TKraSnX1PqtiaKnYCqWNrf9nJMCpkZRmv+LqEiE5DQwPy8/PBsiwAgGVZ5OXl\noaGhIUx0AOD999/HqlWrcPHiRTzzzDMoKSmJut+2bdswZMiQMMHZuHEjXn/9dQwePBjPPPMMiouL\nr8jGQIC/KtERr00VUsVWsrPvSRVbU8VOIHVsTSY7E7an01umTZuGadOmob6+Hk8++SSmTJmCESNG\nSOcPHjyIF198ERs2bJCOLVq0CBaLBQzDYNu2bXjkkUewe/duSeR6Q06OqedFMbBY0q/62kSTKraS\nnX1PqtiaKnYCqWNrMtmZENGxWq1oamoCx3FgWRYcx6G5uRlWqzXmNYWFhSgrK8NHH30kic7hw4ex\nePFirF27NkyI8vPzpdezZ8/GCy+8gMbGRhQVFfXaRpvNeVXfBiyWdLS0dF7xddeCVLGV7Ox7UsXW\nVLETSB1b+8tOhlFd1Zf1hKRM5+TkoLS0FFVVVQCAqqoqlJaWRoXWzp07J7222+349NNPMWrUKADA\n0aNHsWjRIqxevRpjxowJu66pqUl6vXfvXjAMEyZEBEEQRHKQsPDasmXLUFlZibVr18JsNmPFihUA\ngAULFmDhwoUoKyvD66+/jv3790OtVoPnecybNw933HEHAGD58uVwu91YsmSJdM+VK1eipKQEzz77\nLGw2G1QqFUwmE9atWwe1OukihwRBEAOehKVMJzsUXkseyM6+J1VsTRU7gdSxdUCG1wiCIAgCINHp\nMxav/Rivf3D2WptBEASR1JDo9BG2DjfeOXjpWptBEASR1JDo9AE+P3etTSAIgkgJSHT6gG5PSHT8\nXOAaWkIQBJHckOj0Ad1un/Ta1u6+hpYQBEEkNyQ6fUC3xy+9brR3X0NLCIIgkhsSnT7A5Q6JTovD\ndQ0tIQiCSG5IdPqALpnouGReD0EQBBEOic7XhOf5sD0dt5cy2QiCIGJBDcq+BrWNHXj6D/vhcHoA\nAFoNQ6JDEAQRB/J0vgZ6rVoSHAAwp2nh9lJ4jSAIIhYkOl+Dguw0LH3kW9LPei1Lng5BEEQcSHS+\nJsVFGdJrvVZNokMQBBEHEp2vSZZZL70mT4cgCCI+lEjQB9w5vhBpejWa21ywdYQ6Ehw604L0NA1u\nGJR5Da0jCIJIHsjT6QP+deZo3HfXyChP5w9vHsMLrxy6hpYRBEEkFwkTnZqaGsyZMwczZszAnDlz\nUFtbG7Vm69atmDVrFioqKjBr1ixs3rxZOsdxHJYvX47vfOc7mD59OrZs2dKrc4lEr1XDExQdj4/C\nbARBEJEkLLy2dOlSzJ07FxUVFdi+fTuWLFkSJioAMGPGDNxzzz1QqVRwOp2YNWsWJk6ciNGjR+Ot\nt97CxYsX8e6778LhcGD27NmYNGkSBg0aFPdcItFrWXR7/PjkeCMG5V35GFeCIIjrnYR4OjabDdXV\n1SgvLwcAlJeXo7q6Gna7PWydyWSCSqUCALjdbvh8PunnnTt34r777gPDMMjOzsZ3vvMd7Nq1q8dz\niUSvZQEA66uqcehMS8LfnyAIItlJiOg0NDQgPz8fLCs8lFmWRV5eHhoaGqLWvv/++7j77rsxdepU\nPPLIIygpKZHuUVhYKK2zWq1obGzs8Vwi0WtDjuOXZ1ul16+9fxZtnR6lSwiCIAYUSZe9Nm3aNEyb\nNg319fV48sknMWXKFIwYMaLf3zcn5+rDYRZLuvDfHKN07EJTp/T63c8uwRvg8czcW67ewD5CtDXZ\nITv7nlSxNVXsBFLH1mSyMyGiY7Va0dTUBI7jwLIsOI5Dc3MzrFZrzGsKCwtRVlaGjz76CCNGjIDV\nakV9fT3GjRsHINy7iXeut9hsTgQC/BV/NoslHS0tgsD4PL6Y61QBXlonEuB51Ld2YZAlMfs/cluT\nGbKz70kVW1PFTiB1bO0vOxlGdVVf1hMSXsvJyUFpaSmqqqoAAFVVVSgtLUV2dnbYunPnzkmv7XY7\nPv30U4waNQoAMHPmTGzZsgWBQAB2ux27d+/GjBkzejyXSHwRo6q/OTpPep2Zrotaf+SrVix9+SBN\nGyUIYsCQsPDasmXLUFlZibVr18JsNmPFihUAgAULFmDhwoUoKyvD66+/jv3790OtVoPnecybNw93\n3HEHAKCiogJHjhzBd7/7XQDAk08+icGDB/d4LpHkZ6WF/XzHOCs+O9UMAFAzqqj17V1e8ACcLh9y\nMvRR5wmCIK43EiY6xcXFivUz69evl17/7Gc/i3k9y7JYvnz5FZ9LJMOtZqz+P5PBcQHUtXYhL8sg\nnYv0ggDASzU9BEEMMJIukSDVMRk0AIAMk04qFAUAnz9adESxIdEhCGKgQG1w+hGtJvTr9St4Om5R\ndKhJKEEQAwQSnX5EpVJhQ+W3YdSr4fdHZ8Z5vYIQef0kOgRBDAxIdBKAmmWi9nTOXnagvdsLAPD4\nor0ggiCI6xHa00kAGjUTFl5ze/1Y8ephBHjB+6HwGkEQAwXydBKAmg0XnW63XxIcgMJrBEEMHEh0\nEoCaZcKy11wef9h5yl4jCGKgQOG1BKBRq+DnBM/meI0NNfUdYefFhAKCIIjrHRKdBCCG1xrt3Vj1\n+pGo8x4KrxEEMUCg8FoCELPXdn9+SfG8l8JrBEEMEEh0EoBGzcDvD6Dd6VU8T9lrBEEMFEh0EoAY\nXnO6lEcfeP0BcIEAfr7+AD45nvjhcwRBEImCRCcBqFkVfBwfU3Q8Pg5fnrWhwdaN7ftrEmwdQRBE\n4iDRSQAaVgivdbp8MOjYqPMeH4c9R+oBACWDMxNtHkEQRMIg0UkAarWQSODs9qEgOy3qvMfLocHW\nBQAIBASP6OPjDYk2kyAIot8h0UkAapZBR5cXAZ5XFB2vP4DObiH05uMC+LS6Cf+36iTanR7F+529\n7EBtY4fiOYIgiGSGRCcBaNjQr7kgxxh1vrPLK3Ul8PkD6A52LHDHyGp74ZVDeG7T5/1gKUEQRP+S\nsOLQmpoaVFZWwuFwIDMzEytWrMCwYcPC1qxZswY7d+4EwzDQaDRYtGgRJk+eDAD4t3/7N7S1tQEA\nOI7D2bNnsX37dowePRqVlZX4+OOPkZWVBQCYOXMmHn/88UR9tB5Rq0Ojqq0yT+fuSUPh8XHY/fll\n6ZjPH4DbK4iOUnscpbk8BEEQqULCRGfp0qWYO3cuKioqsH37dixZsgSbN28OWzNu3DjMnz8fBoMB\np06dwrx587Bv3z7o9Xps2rRJWrd79278/ve/x+jRo6Vjjz76KObNm5eoj3NFqGWeTrZZL72+985i\n/OPLurC1Pn9AqttREp3Wdnc/WUkQBNH/JCS8ZrPZUF1djfLycgBAeXk5qqurYbfbw9ZNnjwZBoMB\nAFBSUgKe5+FwOKLu98Ybb+Dee+/tf8P7CI069GtOTxPGWY8ZJnhl+Vkhz8dk0MDHBaSwmpLoiAkH\nqqgzBEEQyU9CRKehoQH5+flgWSFdmGVZ5OXloaEhdobWtm3bMGTIEBQUFIQdb2lpwSeffIKKioqw\n4xs3bsSsWbPwxBNP4Ny5c33/Ib4Gck8nPU2D/37mTjz1w28AAPJl4bZssy4YXhPHWEeH0hpt3QAA\nS6ahP00mCILoF5Ky4efBgwfx4osvYsOGDVHntm3bhsmTJyM7O1s6tmjRIlgsFjAMg23btuGRRx7B\n7t27JZHrDTk5pqu212JJj3s+K1MQFkYFDC7KCjuXmxt6X2uuCZebnRClRmfQRN3bEcxyM+jVPb7v\n1diaLJCdfU+q2JoqdgKpY2sy2ZkQ0bFarWhqagLHcWBZFhzHobm5GVarNWrt4cOHsXjxYqxduxYj\nRoyIOv/mm2/iJz/5Sdix/Px86fXs2bPxwgsvoLGxEUVFRb220WZzIhDge14YgcWSjpaWzrhr3MGx\n1LkZhrhr1SrA7fGjM5gq3Wrrilrf2iZ4Oh4v1+P7Xo2tyQDZ2fekiq2pYieQOrb2l50Mo7qqL+sJ\nCa/l5OSgtLQUVVVVAICqqiqUlpaGeSsAcPToUSxatAirV6/GmDFjou5z6NAhdHZ2YsqUKWHHm5qa\npNd79+4FwzBhQnStEbPXcjP1iud1WsEj0wSLSN2+2Hs63W4hs40LUBYbQRCpR8LCa8uWLUNlZSXW\nrl0Ls9mMFStWAAAWLFiAhQsXoqysDMuXL4fb7caSJUuk61auXImSkhIAgpcze/bsqLDZs88+C5vN\nBpVKBZPJhHXr1kGtTp7IoSgUuRnK+zArH5sEj4/Du59dEvZ0PHFEJ1jDIw6FIwiCSCUS9mQuLi7G\nli1boo6vX79eer1169a49/jlL3+peFyeTp2McMGw3ZB8ZVc0PU2LdAhFpD5/AG5VsE5HoTg05OmQ\n6BAEkXokjztwHTP1piJo1AymjCuMu06jFkYg8LwgKJdanKhrcaLIYkJzWzf+590zsHcIdTocFYkS\nBJGCUBucBKBmGdw1vggME7+6RqznEb2Y4+ft+K+XD6KmoQMnattwosYO0b/xk6dDEEQKQqKTRMh7\ntMl577NLsMk6EahZFbhe7Omsf6saj/76o74yjyAI4mtD4bUkQt65QE5bpwdyiUlP08IRowO1nE9O\n0BRSgiCSC/J0kgh1DNFxdHnR2u6Sfk5P04DncVV1RQRBENcS8nSSCCVPJ8esR7vTA0+w8zQgeDqA\nUKvDML3vukAQBHGtIU8nidAotO0ZXmiG28vB4fRKx8zBpqFUq0MQRKpBopNEKHk6I6zmqGMhT6d3\noiOmYBMEQVxrSHSSCLnomAyCNzMoL3rSqDgeQalW5/CZFrR1hicZUCEpQRDJAolOEiEXnSX/OgHP\nzBmPTJNOOvbw3aXIMeslQYoUk0vNTrz05jG8+t6ZsOM0bZQgiGSBEgmSCHmdTm6mAbmZBjhdPunY\n7WVW3F5mxf5jwhyiyALR9z67BADw+sPb59DeD0EQyQKJThIhejpGfejPYtSr8U+3DsHE0lDXbJYV\nOhtEhteO1dgACD3b5Ps41DKHIIhkgUQniQgEhSJDFlJTqVS4b+rIsHVqJtguR+bBeH0c2oMZbvYO\nN3z+kNCQp0MQRLJAopNEFGSn4baxBbh70tC46yRPRxZeaw22yckx69HW6ZFGXgOAn2bvEASRJFAi\nQRKhZhk8Un4jrDnRGWty2KCn4w8EcOaSA7/+62E02LoAACVDMhHgeTS3hToYkKdDEESyQJ5OCiJ6\nOnUtXdj09ikAgpcECKLz8fFGrNt+XFpPezoEQSQL5OmkIOrgiARRcADgfH0HNGoGowZnAkBYrQ55\nOgRBJAsJE52amhrMmTMHM2bMwJw5c1BbWxu1Zs2aNbj77rsxa9Ys3HPPPdi7d690rrKyElOmTEFF\nRQUqKiqwbt066Vxrayvmz5+PGTNm4Pvf/z6OHDmSiI90zWBlqdXjinMACDU6uRl65Gel4cf3lIWt\npzodgiCShYSF15YuXYq5c+eioqIC27dvx5IlS7B58+awNePGjcP8+fNhMBhw6tQpzJs3D/v27YNe\nrwcAPProo5g3b17UvX/7299iwoQJ2LBhAz7//HMsXrwY77zzDlSq+EPTUhVWNgzum6PzcPScDQGe\nR26GAQBQFhQiEQqvEQSRLCTE07HZbKiurkZ5eTkAoLy8HNXV1bDb7WHrJk+eDINBeHCWlJSA53k4\nHI4e779r1y7cf//9AIAJEyZAq9Xi2LFjffwpkge1vIg0Qy+JkCVTH3UeCBWRuj1+fHKiEe29mMVD\nEATRHyREdBoaGpCfnw822EWZZVnk5eWhoaEh5jXbtm3DkCFDUFBQIB3buHEjZs2ahSeeeALnzp0D\nALS1tYHneWRnZ0vrrFYrGhuv3wFmck/HoFNLvdhETycSMbz24aHLWP9WNSr/dICagBIEcU1Iyuy1\ngwcP4sUXX8SGDRukY4sWLYLFYgHDMNi2bRseeeQR7N69u8/eMyfHdNXXWizpfWZHb/DJwoaDCjOR\nk2mAw+lF8ZAsRVuMRj0slnRc3FsDQOhYYEw3wBjs4dZbXB4/9Fo2IWHLRP9Or5ZUsRNIHVtTxU4g\ndWxNJjsTIjpWqxVNTU3gOA4sy4LjODQ3N8NqtUatPXz4MBYvXoy1a9dixIgR0vH8/FAbmNmzZ+OF\nF15AY2MjioqKAAB2u13ydhoaGsI8pN5gszmvahKnxZKOlpbOK77u69ARLAQFAFeXG2la4c+oVUGy\n5dYb8/FpdRMAwN7WhZaWTlxqDtl5/qJdSrPuDW2dHjyzZj/un3YDvvvNwX3xMWJyLX6nV0Oq2Amk\njq2pYieQOrb2l50Mo7qqL+sJCa/l5OSgtLQUVVVVAICqqiqUlpaGhcQA4OjRo1i0aBFWr16NMWPG\nhJ1ramqSXu/duxcMw0hCNHPmTLz22msAgM8//xxutxtjx47tz490TRHrdABAr2VhNgoeiyUzFF57\n+O5SPDNnPIBQ54JLTZ3IShda7HR0hYbC9QYxBfuT49dv2JIgiP4nYeG1ZcuWobKyEmvXroXZbMaK\nFSsAAAsWLMDChQtRVlaG5cuXw+12Y8mSJdJ1K1euRElJCZ599lnYbDaoVCqYTCasW7cOarVg/jPP\nPIPFixdj27Zt0Ol0WLlyJRjm+i1Bku/psAyDGwZlosnuQpqsUaiaZVCYK3Q28HMBdLv9sHd4MGlM\nPj450YT2oOh4vBze/fwSZk4cojhETkTsC8dRSx2CIL4GCROd4uJibNmyJer4+vXrpddbt26Nef2m\nTZtinrNYLHHPX29EZqdN+UYhpnyjMGqd6BH5OR5Nbd0AgFGDM/HJiSbJ09n9xSX8fc956DUspscJ\nm7m9fuleBEEQV8v16w5cx8g9nXiEulEH4PYIopGXlQaVCpKnI4qI2LstFi4PF1xPng5BEFcPiU4K\nIt/TiYda9HQCPDzBUQd6LYv0NK3k6TiCNTuXWpxx7+UKihaNviYI4utAopOCML1MWRbDcH4uAK9P\n8FS0GhZmmei0OoRu1LUNnWEzeCIRPSXqbkAQxNeBRCcF6W2dDMOooFIJITSvTxALnZpBhkkrhdda\ngunXXIBHd1BYlHAF5/P4aE+HIIivAYnOdY6aZdDW6YbT5QMgeDo5Zj1aHC4EAjxs7W5kGLUAIHlD\nSojhNbfHTxlsBEFcNUnZkYDomRyzHpPHRRfXRqJmVdh/LFRbo9UwKMo1Ys+RemzceRJcgMcgixHt\nXV54eiE6PIAutx/mNO3X/gwEQQw8SHRSlF8/cVuv1kU6JVo1i0KLUL+z/3gjbrohF5PGFOBEbZsU\nglPCJRt/3eXykegQBHFVUHjtOkfuvahZBgyjwqDc0DjsH04dCVOwB1u88Jpbtt/T2e3rB0sJghgI\nkOgMIHRaocu32RjyUvKz06DVCMcjw2tfnG7Br/96GDzPw+X1Qxdjnchb+2vw+y3X9wA9giC+HhRe\nG0CIoqFSqfDDqSORYdIGjwvfPbwRKdOnLrTh5IU2dHv8cHs4ZJi0aG5zweNVFp2ahk7UNHT04ycg\nCCLVIU9nACF6OgAw89YhmDRG6MQtejpeH4dNb5/EniP1AID2brGA1Itujx+ZQQ8plqfT7fZJnQsI\ngiCUINEZQIieTiTy8NqeIw3Y9PYpAKFO1O1OD1wePzJMQofqWHs/XW4//FwAb31ci7OXe574ShDE\nwINEZwAh93TCjgfDa13u8OJQsYD0q8vtcHs5DC0QBkF5YmS5Od1CgsHf95zHvqOxp8ISBDFwIdG5\nzpl56xDpdWR3ahGtWhAje0doOBwXCEiezoHgMLhvFOcAiBdeoww3giDiQ6JznfPDqSNx/7QbACDm\nZFSGUUGjZmCTic6ClR9JBaGN9m5kmLQozDVCzTKKouP1cWG929qvcEgcQRADg16LzoEDB3Dp0iUA\nQHNzM5599ln89Kc/RUtLS78ZR/QN+mBYLd44bq2agb3DE/P8jUOzoVKpoNMoi05kaK6zm0SHIIho\nei06y5cvB8sKD68VK1bA7/dDpVLhv/7rv/rNOKJvMOiEzHiOjyM6Gha2dnfM8xNGWwAI+0JehZTp\nLnd4OK2jyws+zvsRBDEw6XWdTlNTEwoLC+H3+7Fv3z588MEH0Gg0mDx5cn/aR/QBBtHTidMhWqdh\n0dYZ29MZOzxbWqfo6bjCRcfrD8Dt5STBi+TwmRZcbu3CrNuG9WQ+QRDXEb0WHZPJhNbWVpw9exbF\nxcUwGo3wer3w+2O3w5dTU1ODyspKOBwOZGZmYsWKFRg2bFjYmjVr1mDnzp1gGAYajQaLFi2SRG35\n8uX45JNPoNVqkZaWhp///OcoKysDADz44IOor6+HyWQCADz00EO49957e/vRrnv02qCnE6c7tFYT\ncnq/f/swDMlPxz++rMfsycPh8XLQBJMNtBpWMXstMrwGCCG2WKLz0pvHAIBEhyAGGL0WnXnz5uGf\n//mf4fP58LOf/QwAcOjQIYwYMaJX1y9duhRz585FRUUFtm/fjiVLlmDz5s1ha8aNG4f58+fDYDDg\n1KlTmDdvHvbt2we9Xo8pU6bgZz/7GTQaDT788EMsWrQIu3fvlq79z//8T0ydOrW3H2dAIe7pxJv6\nKdbwGHRqzJ4s/E1vHmVRXKe8pxOdrdbR5UNeVvR71fUwpZQgiOuXXovOo48+iunTp4NlWQwZIqTh\n5ufn45e//GWP19psNlRXV2Pjxo0AgPLycvziF7+A3W5Hdna2tE4eqispKQHP83A4HCgoKAgTlPHj\nx6OxsRGBQAAMQwl4PSGOt44nOmKBaHqw+WcsdBoWHQpJAl0uwdNRQRh/AMTOYDteY5de8zzf66F0\nBEGkPlfUe2348OHS6wMHDoBhGEycOLHH6xoaGpCfny8lIrAsi7y8PDQ0NISJjpxt27ZhyJAhKCgo\niDr36quv4q677goTnJUrV2LVqlUoKSnB4sWLkZ+ffyUfDTk5pitaL8diSb/qaxOBwaQHAHx7wuCY\ntqYHW9xkmfVxP4/ZpEOb0xO1xs8DGjUDo16DLrcPPn8APMso3isgE5nMLKMkeHKS/Xcqkip2Aqlj\na6rYCaSOrclk5xWF1xYtWoRbbrkFf/rTn7Bp0yawLIsHHngAjz32WJ8adfDgQbz44ovYsGFD1Lkd\nO3bgrbfewquvviodW7lyJaxWKziOwx//+Ec89dRT+Otf/3pF72mzOeOmFMfCYklHS0vnFV+XaNY9\ncyeKrBkxbW1tcwEAbhgUew0AIBBAt9sXtaahpRMZRi1YRgWjwYC6li7UN3Yo3qvV3i29rmtol0Yr\niKTK7zRV7ARSx9ZUsRNIHVv7y06GUV3Vl/Vex6bOnj2L8ePHAwC2bNmCzZs3429/+xtee+21Hq+1\nWq1oamoCxwl7ARzHobm5GVZr9OTLw4cPY/HixVizZk3UftF7772H3/3ud3j55ZeRm5sbdn9A8KAe\neughHDlyBAEaqRyGTsPGDWO5vEJ47K7xhXHvo9Wyil2mHU4vMk06mI1a5Jr1MOrVimE4AOiWzeaJ\nN8OHIIjrj16LTiAQgEqlwsWLF8HzPEaOHAmr1Yr29vYer83JyUFpaSmqqqoAAFVVVSgtLY0KrR09\nehSLFi3C6tWrMWbMmLBzH374IV544QW8/PLLGDRokHTc7/ejtbVV+nnHjh0YNWoU7fVcIU/MHov/\nuKcM2WZ93HW6iOy1AM9j79F6tDhcyDBp8fDdpXhwRgnS07RSG51I5O1y4o3IJgji+qPX4bVbbrkF\nzz33HFpaWjB9+nQAwMWLF5GVpZCepMCyZctQWVmJtWvXwmw2Y8WKFQCABQsWYOHChSgrK8Py5cvh\ndruxZMkS6bqVK1eipKQEP/3pT6HRaLBw4ULp3KZNm6DT6fDoo4/C5xOyp/Ly8rBq1arefiwiiDXH\nCGuOscd1eg0LPxcAFwiAZRicutCGjTuFrtTfGJmLvKw0AMKguJii4wllusUbkU0QxPVHr0XnhRde\nwMaNG5GdnY2HH34YAHD+/Hk89NBDvbq+uLgYW7ZsiTq+fv166fXWrVtjXn/gwIGY5958881e2UB8\nfaQxCN4A0vQMTl5ok85lmkITSc1GLS43h6dGe30cXt5xEhebnDDo1HB5/PD6ydMhiIFEr0UnKysL\nTz/9dNixu+66q6/tIZIcg04QHbfXjzS9GqcvhubmZAbn7QBARpoW1RGezskLbfjsVDMAIDdDL4gO\neToEMaDo9caHz+fD6tWrMW3aNJSVlWHatGlYvXo1vF5q7DiQMBkEb6az2wePjwsbTy3PQks3atDt\nEYa6ichzA7PSBYHq7Z5Oo70bjbKsN4IgUpNeezq//vWvcfToUSxfvhyFhYWor6/H2rVr4XQ6pQ4F\nxPVPepogLJ0uLzyNHLgAj7JwARBhAAAgAElEQVQROTh23obcjFASgjlY99PR5ZWSE5yyGTuiV7Tr\n4EWYjVqMLMpQfL8WhwufnWrGGx+dAwBsqPx2TNsuNnVi16cXMf/u0pizgwiCuLb0WnR27dqF7du3\nS4kDI0aMwI033oiKigoSnQGEKDpnLjnQ6hC6Uj98dyn8XCAs8y0jLSg63SHR6XSFvGJRdL663I7/\n/3++iCkmf3nvDI6cs/XKtg07hf2i6d8cjOFW8xV+MoIgEkGvRSdWm3pqXz+wSA+KSdXHFwAIbW9E\nr0aOKShOzmD3abfXHzavR550oERbpwfPrNkPo773TTM0Qe8mVtYcQRDXnl7/Hz1z5kw8/vjjePLJ\nJ1FYWIi6ujqsW7cOM2fO7E/7iCQjTa8Go1IhEPyyMWa4chsjsbO1WEj6xKo9YedF8YrFF6eFhAN5\n9+pssy7WcgDCrB9ACMkRBJGc9Fp0Fi9ejHXr1uG5555Dc3Mz8vPz8b3vfQ9PPPFEf9pHJBmMSgWd\nloXL48ftYwswJzgKOxJRANwK3QsASKIVi9OXQllxYhNRcbxCLMRbtjhiD6MjCOLaEld0Pvnkk7Cf\nJ06cGNXg84svvsCkSZP63jIiaRFb19w4LDuqb5qIXhMSHXnbnLxMAwbnmzB+ZKiNkVYdvukfCPCo\nrg11or7rpiK4vRzOXnYgHp3BRIXWdvJ0CCJZiSs6P//5zxWPiz28xLb077//ft9bRiQt4ogES6Yh\n5hq9NlTP0y7rwaZiVHjyB2Vha0WvSKS5rRsuT0ioss06NLe54o5mAIShcQCF1wgimYkrOh988EGi\n7CBSEEtm7D5tGjUDlUqow+lwhkQncqy1uBYQPBw/F0C9owsAMK44B0fP2ZCVroOtwxNW8xNJgOcl\nT0eesEAQRHJBxQzEFZOfJXg4SllrIiqVCnqtGidq2vDqe2cAAEPz0/HkD8ZGrRW7Emx8+yQe++0/\ncKlJaMM+/gYhBJeVroeaUYHjYns63W4/AjwPrZqhJqIEkcRc0RA3ggCAynm3wN7h7nHip17LhnUs\neOq+ccgwRWegiSKx/1gjAOB8XQcyTFrcNqYAbg+HUYMzcPRcK/xxxlWIadKWTAPqWrvg5wJUIEoQ\nSQj9X0lcMRlGba+KL/URezWRadJTby4CAPj8Qtdqka8ut6EwR5goOvPWIWAZBmqWievpOJxCSE3s\nikDeDkEkJyQ6RL+hixhDzTDhntGD3y3BnG+PBCB0rRZpsndHFY+yjApcgI9ZjHzmkgMqFTBykNBO\nhxqJEkRyQqJD9BuRno4SojDJPRM/x0OvC4/8ssFQWawMthM1dgy3mpGdTp4OQSQztKdD9BtiV4Lx\nI3Mxd3r8IlJbe3hBZ6RgqVnBS+I4HpE1oqcutOF8QwfKJw2Tzfsh0SGIZIQ8HaLf0GqEf15FFiNy\nM5RrekRPp8HWFXZcFCwRNjh+PDKZ4M+7TmHlXw8jLysNd91UBJ1WWCcfDnfqQhvWvHmsxy4IBEH0\nPwkTnZqaGsyZMwczZszAnDlzUFtbG7VmzZo1uPvuuzFr1izcc8892Lt3r3TO5XLhqaeewvTp0zFz\n5kx8+OGHvTpHXDvESFh6jK4FQMjTaYiYlWOI4+lcbOrEL/78GS63OHHgRBNuuiEX//XQBGSl6xTD\ndf/9vyfwxZkWKholiCQgYeG1pUuXYu7cuaioqMD27duxZMkSbN68OWzNuHHjMH/+fBgMBpw6dQrz\n5s3Dvn37oNfr8fLLL8NkMuG9995DbW0tHnjgAbz77rswGo1xzxHXDr9f8EriNfcU2+U0t4ULQrSn\nI4iOnwvgXF07aho6seTlgwCAm0dZkBbsRq2TjdMWyTRp0dHlxeXmLuRnpQEIddMgCCKxJMTTsdls\nqK6uRnl5OQCgvLwc1dXVsNvtYesmT54Mg0EIw5SUlIDneTgcQr+tt99+G3PmzAEADBs2DGPHjsWe\nPXt6PEdcO3zBEJfREPu7jSgSbZ3hezriWGwRsebGH+Dh84eH2Ibmp0uvxT0dr8zTEWf3XG5xwtbu\nxvHzNjyxag9eefc0jeYgiASTEE+noaEB+fn5YFnhgcCyLPLy8tDQ0IDsbOXW+Nu2bcOQIUNQUFAA\nAKivr0dRUZF03mq1orGxscdzvSUnx3RF6+VYLOk9L0oSEmprcB8mLzc95vtywTUOZ/gMnHxL+DVZ\nme0AgIwMA5iITIJxo/Ol7DYm6CFp9ZrQ9UGP5kStHW8fuABvULQ+OFSHB753IyxB7+dqoL9935Mq\ndgKpY2sy2ZmU2WsHDx7Eiy++iA0bNiTsPW02JwI9NJRUwmJJR0tLZz9Y1Pck2lZLsFCT9/tjvm9X\nsElnW6cHaTo1uj3C/ByPyxt2TXeXUPzZ0uJEa1s3dFoWP5w6Eq0OF+z2UBJCt1vov2azd6G5uQNH\nztlgC+7lfHVZEC6dlsX4kbn4tLoJjU0dUPljZ7q1dXrwm9cOY9F930BuRINT+tv3PaliJ5A6tvaX\nnQyjuqov6wkRHavViqamJnAcB5ZlwXEcmpubYbVao9YePnwYixcvxtq1azFixAjpuDg4TvSMGhoa\ncOutt/Z4jrh2/Mu0kbi1NA/WnNh7a2k6tTQvx2zUwuPjwAWU6nSCiQQBHi6PHwYti6k3FUXdTytL\nJDh10YHVbxwFAIwdkY2h+ekYnGfCxNJ8HD7Tgk+rm3osIv3Hl3VosHVj79EG/GDKiKjzh8+24KvL\n7bhv6si49yEIQiAhezo5OTkoLS1FVVUVAKCqqgqlpaVRobWjR49i0aJFWL16NcaMGRN2bubMmXj9\n9dcBALW1tTh27BgmT57c4zni2qFRsygZkhV3jZplYAxmtxn1ammPJzJ7TUqZ5gJweTkYdMrfl9Qs\nA5ZRwesPhHW0Lswx4t47izGxNB+AbO8njpcDAB3BztWxmpt+Wt2Edz+7ROnYBNFLEpYyvWzZMrzy\nyiuYMWMGXnnlFSxfvhwAsGDBAhw7dgwAsHz5crjdbixZsgQVFRWoqKjA6dOnAQAPP/wwOjo6MH36\ndPzoRz/Cc889B5PJ1OM5IvnJCLa8SdNrpBTqWMWhfi4At8cfU3QAQVA8Xi5saqlRr45YE6znieHp\n/Oa1w1i37bjUSDSypY+Iw+kFF+DRHrEnJcfn5/D2gQtxRzMQxEAhYXs6xcXF2LJlS9Tx9evXS6+3\nbt0a8/q0tDSsXr36is8RyY85TYs6dIV5OpEp02pZGxyX1x/lCcnRaYTxBh2y4XHGiFohrTq2pxPg\neVTXtgEI9XLzxRAMsdHo8RobvjEyF2aF9PCTFxzY8tE5DLOaUTo0vudHENc71JGAuOaEPB01dFoW\nOi0b1Rw0VKfDw+3hovZ85Og0rCA6XTLR0UeIThxPp0lWqCoOhotM0waEWh9RdDbuPIVfvXJI0R4x\nzNft9uFErR1fftUa03aCuN4h0SGuOaJ3kKZXQ69hFUNnIU8nEPR04ofXvL5AmOhE3lOcVupVaAwq\nnwFkaxcy33wKHlG32x8mWo0RXRVEutw+af1vX/tSSm4giIEIiQ5xzRG9DpZhoNOySFMQHdHT4Tge\nLg8HvS5eeE3wdNplohO50R9KJAj3YHiexxenW6Sf/cEZPkoekb3DHXVMiS63P+y/wuvosd2AUEtE\nzUqJ6xkSHeKaI3Ub4AKYNKYA/3Tb8Kg1Ysr0V3XtwZTpOOE1LQu3l0NntxfFhWZMvbkIY4aFZ0rq\nYuzpfHKiEYfPtkbtvSjt6dgjOmOroByGEwWmWdb77WJjdN1Eq8OF3772JTa+fTLmZyOIVIdEh7jm\niKEujuNx6435mH1ncdQaUZje/ewSgOhwmZx0gwad3V50dHkxKM+EB79bIr2H9J4x9nSqa9tgNmrx\n4IySsOM+X7RH9PGxegDA9AmDMSTfBB7K3k+XS/BwaupDYbsLTc6odaLXVduQ/AWHBHG1kOgQ15w7\nv1GECaPzMPPWITHXsBGJBfHCa2ajFg6nF50un2I2GQAwKhXULBPl6Vxo7MSwgnRkpeukY5kmbdg6\nnufxP++cxs6Pa2FO0+Cf7xqBf5kmzAtqaY/uZC12SbjcEhKautZo0RFTqmNlysXi0JkW/PF/T1zR\nNQRxrUjKNjjEwCJNr8YTs8fGXSN6OiIujz/GSkF0xAe4XDwi0aqZME/H4+VQb+vCLSUWKXU7P8uA\nAM+HCUGDrRsffVmP8tuHo/xbQ6BRs7AEW+S0OhQ8neBeDhfgwTIq5GToFfeIxHEMYnKDrd0NHxdA\nQXb83nB/eFOoc/vR98fEXUcQyQCJDpESiHs6ImXDc2KulXs32WZ9zHVaDQOvj8PKvxyCNceIUxfb\nwPPA0AKhOeKvfvQtmAxavPDKF2HhtQabkKU27ZtDpIQEcXxDpys6QUCeNJCXZYCGZRT3fkTR8XFC\n5t3idR/DqFfjpaemxPwMcrhAQOrcQBDJCokOkRKoZQ/TXz02CXmZypNIgfCWNTkZ8USHhdcfwPn6\nDnxV1wE/F0Buhh6jg6178oLdpzVqJizLralNEJ1CixFdwZEMalYFRqVSTMHulmWt5WelobPbq5iC\nLXo/Xl8Av/jz5wDCM956wu/nwcYeXUQQSQF9LSJSArmnE28SKQBkyEQnu4fwmq3DDa8/IIXjnpkz\nXrGmRy4SjfZumI1apMkKTlUqFXRaJirdmef5ME+nIDsteL/Yng4A2DrcyMsyICeOpxbg+bB5QJGj\nvAkiGSHRIVICeSJBZF+2SOSeTk892hptoYJOlUrZM9JGiESzvRsFWdGeljZYHyRHEDQeovX52Qao\n1YxisoAnbPCcFjcOzVL0iADA7fXjkRUf4p2Dl6RjfgUhI4hkg0SHSAnko6V7GjOdnhbfExLRqhk4\nZXswOWZ9VMICIHTLFsNr7U4P6m3dyFPY3NcpiI4YWssMelwF2Wkx93S8Mi8pN9MAjZqFJ4aQiO15\ntu+vkY5dadYbQVwLSHSI6w4l4VBCG9E52hJjn0i+p/Pf20/A7fVjQkle1DpdsP2OHDHLrjDXCEal\nQkGOsVfhtXSDBloNE1UfJCKKmTycJ3ZPIIhkhhIJiOuSWbcNw6C8+OMttMGCUZUK4HkhsyzWOn8w\nzNVo78ZtYwswrjg6e07J0xHHK9w1vgj3f3skMoxaaGWekxyPTGDS0zTQqhkEeB5+LhAlpEptdCi8\nRqQC5OkQ1yU/mDIC3xwd7Y3I0QRb4RTlGjF2eLaikACAJpjlxvM8nC5f1JgEEXGkgojL40dncLyC\nyaBGkcUUfN+ePZ3RQ7Mk+5TWditktfVVIoHL48fvtxyBrb13veUI4kogT4dIGUYPyezTeTTtXcJY\ngptHWTB7cvQoahENK4TX3F5hlLYpluho1XDImow++bs90mv5fCBNjEQCr49DpkmLp+eMxyCLCR8c\nuiwc9wdgiEjCU/Z0lMNrPj+Hf3/uHfzLtBtw0yhLzM8p8unJJhw9Z8P/7q/Bv3+vtMf1BHElkOgQ\nKcNP5t7cp/cTCynvHF8Ud51WI6RC/3nXKQDRs3lEdJpQyrQzokhUnnGnUTNSKKzJ3o39xxtxR1kB\nPD4OWg2LQTKPCAB8PdT+iMRKJKhv7UZruxtbPjrXK9FxBe+dpqfHA9H3JOxfVU1NDSorK+FwOJCZ\nmYkVK1Zg2LBhYWv27duHVatW4cyZM3jwwQfx7LPPSud+8pOfSKOrAeD06dNYs2YNpk2bhpdeegl/\n+ctfkJcnhFNuvvlmLF26NCGfi0hd5n9vNJodrritcoDQw//gyWYAiO3paFipOPT0RUfYuTDRYRlw\nAR5cIICPjzei6uNaHD7bAkuGIWwsdmi6qVLnaj9YRoU/Lb4L5+s78Pz/fBFzHHaDrQuAkIbdG7qD\nyQ9KIyYI4uuSsH9VS5cuxdy5c1FRUYHt27djyZIl2Lx5c9iawYMH4/nnn8euXbvg9YbPnF+5cqX0\n+tSpU/jXf/1XTJ48WTo2e/bsMJEiiJ7IMOmQYYovOEDo4S8SS3SEOh3hwX/6YlvYOZ1cdIIdrv3+\nUOFoo60b6QZNhOgEPR3FPR0f0vRqqIKNS4X7KYtOXasgOhebnJj/qw/w+4V3xGyECoQy7mLVOB2o\nbsRnJ5vx43vHCd6ZmomZxt5g68L5+g7cXmaN+X7EwCIhiQQ2mw3V1dUoLy8HAJSXl6O6uhp2uz1s\n3dChQ1FaWgq1Or4WvvHGG5g1axa0Wur5QfQ/kfsnsRMJBE8nwPM4fDY0CE4VPCeiCYqE189JXgUX\n4GHrcEOnCf0vKYqTx8chEOBx+mIbmh0unLnkQJfbL3VEUAe7NfgD0Xs6re0uHDjRCCDkwdQ1R3e4\nliOuiyUkR8/ZcPhsK87VtePx3/4DH31ZH/NeyzZ+hpd3nIzphREDj4R4Og0NDcjPzwfLCv/jsSyL\nvLw8NDQ0IDs7u4erw/F6vXjrrbewadOmsOM7duzAvn37YLFY8OMf/xg33XRTX5lPDHAiO1rHTiRg\nwQM4eaENtg4P8rMMaGpzQRPhCWhkHox8b6bF4Zb2c4CQh+XzB7D7i8t47f2zSE/TgFGpMMhihDG4\n56JWx/Z01v79OGwdnrBjGnXsjg6/fe0wTtQKXlosoRCz2lb85RAAYRxELEQvzeH0IDcjdr88YuCQ\nckHb3bt3o7CwEKWloaya+++/H4899hg0Gg3279+PJ554Ajt37kRWVu8znXJy4td0xMNiSb/qaxNN\nqtiaTHbOryjDYGsG/ryjGgAwdFCWJBxyO3OCDUL3Hm2EVsPiu98ahv95+yQCfPi67CwjACA9wxDM\nTFNLwpaRrpfWtruF/SFDmhbdXmEAnNiJIDtDjyxzcG0wMqBP00rXur1+uDx+1DZ2ojDXCKNBg7OX\nhH0mg1Gr+Putb3VKggMAeoPyujanEPoWi1Fzs9IU14WFBVl1r/+myfS374lUsTWZ7EyI6FitVjQ1\nNYHjOLAsC47j0NzcDKv1yuO8W7duxb333ht2zGIJZeTcfvvtsFqtOHv2LCZOnNjr+9psTgQUwhM9\nYbGko6UlNSY9poqtyWjnnWUFkug42oQ9kkg7vR5BEA5WN2LqzUXQB8NeXCAQts7tEh7aTc2daHd6\nUJibhnN1gqjwsrVOp+BRtNq7gIganEtNncjLNKClpRMdwTTtNkc3Wlo6cb6+A7/c/DnKRgh1R4+U\nl+LwObskOs0tTrQoFMK+/+nFsJ/bO1xRfwc/F4AtYlBdh9Mdta6t04Nn1uyXfj5/yY5cU8/tiTo8\nHC7WOTB2ROzRFclCMv47VaK/7GQY1VV9WU/Ink5OTg5KS0tRVVUFAKiqqkJpaekVh9YaGxvxxRdf\nYNasWWHHm5qapNcnT55EXV0dhg8f/vUNJ4grQL5vM33CYBiC4S8+4ruMuKcjhtes2UbpXLpsg19M\nJPD6AmF1PoDgZZgi93SCnsWFJuEBc+y8DTlmHYbkp4fd1xPRRLTJ3o3X3j+Lo+dao94jEkenJ+rz\ncArrLkXsG7V1eqLWKPHU7/6BVX870qu1RGqSsPDasmXLUFlZibVr18JsNmPFihUAgAULFmDhwoUo\nKyvD559/jqeffhpOpxM8z2PHjh14/vnnpSy1v//975g6dSoyMjLC7r1q1SqcOHECDMNAo9Fg5cqV\nYd4PQfQF9945Iu7DUy46BdlpUjeCSMQEAZ8/gC63P6xB6a035kuvQ9lrHDiFbgMFOUI4T8peC3rq\n4vvePWko7hpfBEalCnuPyP5wf951CqeCKd43DMrA2cvtAKD4nraO8C4FGSat4t6P6H09dd84rNt2\nAm98dA752WkYPzI3ai0xsEiY6BQXF2PLli1Rx9evXy+9njBhAvbs2RO1RuTxxx9XPC4KGEH0J3dP\nGhb3vLjPI/ZwS4tRRCp6Ot1uP/xcAGl6NdJ0anR7/CjKDXk9GlmdjtJ4a6soOhGJBI5OD0wGDe69\ns1haKy/0jJz5I48qTxidh7wsA/Yfa1T0YFqDSQTfvrkIaXo1DpxoUvSIOoLCN2pwJnieBxfgsfqN\no9hQ+W3F3wkxcEi5RAKCSFZET+f2sQUAYhdXiuLkCLbhMeo1+NVjk8BEZChrNWJqdQBehbk6hUGB\nYlQqsIxK6kjgcHqjCl7lwhDZlFT+tkPyTJg+YTCOfGVT9GAa7d1gGRXun3YD1CyDz061KHpEHV1e\naDUM9Fq1VNwab9qrYGPv06p9fg5tnR5puiuROlDDT4LoI4qLMvDzh25B+W3DAEBKaY5EFJ32YBZY\nml4Nk0ET5RmxjAoqldCTTcnTkU9IZVmV9NBu6/QgM6LodXihWXodKTqtssQAsTO3cL9oD6a+tQt5\nWQYppKdmVYoeUUeXVypA/dH3xwCIXd8kv6a3fHCoDks3fEb1PykIiQ5B9CHFhRlSTY4oLvLaG/nx\ndqfg6cTqcaZSqaDVsPD5A1J7ncjz0j1ZRmr42eb0ICs9vHD6hsFZWP1/JkOvDZ/54+cCsHd6kGPW\nYUKJReorp2YYRQ+mvrVL8rDEdUoP/vYurySKt96Yjwklliixi6TNGdov4yOzFSJobXfD4wsV1yaK\ni02daLJ397yQiAmF1wiin1CpVFj2799Etjl8BLZY9NkYfHjFaiAqrGWC4TXhwS50xB4eNr4bEJIJ\n/IEA/FwAnV3eKE8HEIpa5TN//FwAf3qrGjwPfP+O4Zg8rlBayyp4MD4/h2aHCxNLQ8kOalal2Amh\no9sbFk7TaVl4vPEFwiFL0uACvJSVp4TYUNXl8cdt6dPXLNv4GQDQ3tTXgDwdguhHhuSnR3UwED2d\nUxcdyDHrpYQAJbRqBj4fB6+Pw9D8dPzHPWUYZDHBmmMMW6dmhc7VK149BB6I2cRU3pT0zCUHPj8l\nNDEtyg33xtRstAdz7LwdPI8wT4dlGXAxstfMsvCfXqOWBtrFQp4ZqNRvTo4zmKig1G37avBzAWze\ndSruDCF5Aoa7BwElYkOiQxAJRiObAvqfD90SVYMjJ9OkQ6O9G15/QEq1VkKtZuD2cjhX34GsdB1u\nURinDYhNSYWH5/HzdqhUwM8fvAUjZHs+AKBmVOBkHsyXX7Vizd+PIT/LgDHDQ/V1aoW9Hy4QgLPb\nF+aB6LTRU1UjaZft6cQa0yDSGfR0+iq81tTmwkdf1qO61h5zjdg4FQDOXGrvk/cdiJDoEESC0WoY\nTB5nxf93//geu1yXjcjB+foO2Nrd0KnjiA6rQrusPif2+AVhuumHh+uw6+BFjB6SheKijKh1LMuE\nicmmt09hcJ4JS/7tm2H3VvKIulx+8ECYp6PTsvBzwujtz04147HffASfn5OamArXhRqrKvWRC8j2\necR2QK5eeDrtzp4LU0XPRWmMhMjlllDB61d1jpjriPiQ6BBEglGpVPj375XixmE9d+QYNzIHPIBm\nhwtaTexGnWqWQWfQU4g1kgAQPB2vL4B3Dgotb6bepDzATp4N5/Vx6OjyYkJJXtS9WSba0xG9ELk4\n6YO2u70ctn50Dl5/APYOD1b85TAq//sTAIBTJiDie19o7MS6bcfxhzeP4ZEVH2Lb3vPS2HCgZ0/n\noy/rsOgP+3G5h87aYugvnjd2udkJnYaF2ahFR1f05Faid1AiAUEkMUPy04Xx1v5AXNHRsAyag55O\nvOFrOg0Lp8uHLpcPU28uwoTRymE4NaOS9mrEVGZ5ira0jg1luTXYumBrd0t7ViZZFwRxiJ3Hy0n1\nR07ZyIjf/e0ImttCWWG+oJC99v5ZnL7kkFK0z1xyYOVfDkt7PvH2dAI8j48O1wmfIUZ3CBG3RxAb\npSxBkcstThTmGuH1cYrjwoneQaJDEEkMo1Ih06RFi8MttcVRQs2q4Ao+OOONmdZpWbg8fnS7/UiP\nUzejZhm4/MIDXdxrMSuKTsgj+vn6TwEAT/5gLACE3V8cYuf2cVKnhUZbSGSOnbeF3dfvD+BiUydO\nX3LgnikjMHmcFX96qxonL4QPx4scOyESCPD4j9/vkTyYnpr5iuG1WJ4Oz/O43NKFm0flotHWHRYK\nJK4MCq8RRJIjpj9HTjCVo5YJUnxPh0Fbpwc8Ys8FAsS9GuFB3RFHdCL3foBQKnhYeE3u6QRtrZdt\nzItkBrPufFxA2kO5pcSCDJMurH+cSKzwWnuXNyxbThQTLhDAH//3BGobO8LWi2uVinDF+zldPhRZ\nTDAaNHC6EpO9xvM85v/qA2zfV9Or9f/xuz2o+ri2f436mpDoEESSIyYbaONlrzEy0YlX96Nhpaw0\nk8JDXIRlVPAHw2ZigkLM8FpEIoE4pkEuOmKLII/XL4UJ6xRER6xp8vsD0vC5nOAxJZEUw2s8z+N4\njQ08z6O61o4PD18OWyeKTlunB59WN+HXfz0cdl5KJIjh6YgCOMhiglGvSVh4TUxs6I3oBHge3R4/\n3txzvtf3t3e4FYuA+xMSHYJIcjKCqcfx9nTkXkBPezrSNYbYRZViceiZSw68feACgBjhNYVEgq/q\n2qHVMGH2imnhcu9D9HTyZbN9RNHxcQHY2t1IT9NI95GPZzAbtcgx66Tw2qcnm7Dq9SP4x5F6/Oa1\nL1H1sWDzA9NHAQA8QQ9GfH8xFCnSUyLB5WbB1kEWI4wGdcJERwzjxS6TDeGL4aXFwunyofKPB/Dl\n2daeF/chJDoEkeSIezTx9iVyZdX/8TyiHFl3hJ7DawH86tVDaHG4wTIqaTM/al2wE4KI0+WL2i+S\n7+mID3axY/VP5t4sFZzKPR17h1vR3vQ0DX7/4zuQm2GQwmudwWyyA8cbw963rFgYBueRxEY5LCYl\nEsRImba1u5GmUyM9TQujXgOvT7k10dXQ7fbHLEoVPTlW4XcfSU91UJG0dXrg5wJR85H6GxIdgkhy\nRNGJ9cAEgNyM0MNZ3pMtEnk3AaU9EhE2ojiUiyF4okck1s2ImCK8qFB4jYsarZCeppEy3rLMoT0d\nW4cbObLPJdorelxperX0UBZb5py5HF60mRO8nygQ8mw3MbMN6Dm81ub0SPtNYuNSpyyZgOd5vPru\nGdQ0dChe3+70YNenF1N97PAAABpASURBVMNqjUT+8/8ewOJ1HyteJ3pUbJyWQCJXKjpiRl+8fwf9\nAYkOQSQ5YrgsXk2KJSP+2AARuejE6/qsZhk4elFUKYpTe3BMg+gNiYkDIuLPbi8Ht+zhaNCxULOM\n1KVBCq/5g6Ij83RE70nsdJCmD4W55DU+cs1lGQZqlpHeUy7cm985jQZbF37918PYH/SQYj24HU4P\nMk3C+4oel3xIX0eXF+8fuozfvHYYAZ6Hy+PH3iP1+OK00GbojX+cw98+/ArVNdEdDxzO2OncYsKC\nOnLuhQJy2//0vyd6bBEk2q8UNu1PSHQIIskZWpAOABip0DlARO4RxENpc18JllVJYZfvTBiEZ+fe\npLhOFBl7cNP/e98aAkDY15Gjk4pD/WGNP0WxET0d8X4OpwdeXyCsWaopKDYZwYd/hlGHji4vAjwf\nlsI8aUxBxHsz0gNZFO7pEwYDAOpbu8PSsCOz146dt6Hb7YPD6UFWMKFDHFnhlHl39mDfOJeHw1v7\na/Hk7/Zg49unsObvxwGE9uPO1St7QrHoDoqqUmgzErnoHKhuwqcnm+KuF73T9AQ2TAUSKDo1NTWY\nM2cOZsyYgTlz5qC2tjZqzb59+3DPPfdg7NixUdNAX3rpJUyaNAkVFRWoqKjA8uXLpXMulwtPPfUU\npk+fjpkzZ+LDDz/s749DEAljSH46fvvk7bhzfGHMNeKDuK+QP+S+962hKBmSFXedPTjGetLYAug0\nLCruGB62jmGEeiNxJIHU5DTollTcMRxGvRo3Bvu61bcKadfyTtVSeE0mPlyAl4pdRUYNzoQKwLjg\nfo5Oy8Ibsadz96ShAIBGe3gGnfzB3dHlxe/+dgRr/n4c7U5vKLwWzA6Uz/8RRRcADpwI31eScyqi\nzqjbHR6ii6QrInyoRJfbh3P17dJnFIk1z0mks9sLRqWKW9fVHyTs3ZYuXYq5c+eioqIC27dvx5Il\nS7B58+awNYMHD8bzzz+PXbt2weuNdjlnz56NZ599Nur4yy+/DJPJhPfeew+1tbV44IEH8O6778Jo\nNEatJYhUJFbXaBEm+PCOl7km8sz948PGCCghjk7QqhnFVGlpXfBh2Nwm9E/LNOmw9ukpivtKg/JM\nuNTshNvL4ZaSPIwdni29z6jBmXjpqSkwpgueTV0wRTk/OyQ6JoMGZqMWg4OD5sT6pQ6nN2x/ZXCe\nCX/6yV2SDfJxDt1uP9SsCmajFpkmLc5HeB7yPR3xM4meUGaUpxN6RrV1hhIBNLJ6KrFtkCiKNcH6\noHcOXoTJoMHLO05Ka/1cIOxaALIsudiis/vzy9jxyQVpWF5v6ez2wZSmkf7tJIqEeDo2mw3V1dUo\nLy8HAJSXl6O6uhp2e3h8c+jQoSgtLYVafWVa+Pbbb2POnDkAgGHDhmHs2LHYs2dP3xhPECnCb564\nDS/86Fs9rhszLBu3l1njrhE9GLNRGzcxQVx3rr4d1pw06DRszPWDLYLo8LywxzNqcGZUs1ExzHa5\npQsqFWCReTpqlsFvn7wNtwXHgYti6OjywOn2YWhBOhaU34hhBelgGUZ6mAqdtYWwmcvjl4TZmmPE\n2YjEA48se62pLXxYmyg6omfQJdszsctEXN4YVPRQxFCW1xdAu9OD1z/4KkxwAOXMOfE9PD4Oh860\noPK/P4lqsNre5RWG8XWEZ8D1NEqis9uX8CQCIEGi09DQgPz8fLCsoOIsyyIvLw8NDQ1XdJ8dO3Zg\n1qxZmD9/Pg4fDhV31dfXo6go1LjQarWisTG2i0sQ1yPZZn2fxefFh2VPI6bFDe6ahk4MKzDHXSt6\nKEDs/SRRxAI8j9wMfdReBsswkqiJIcV2pxddLj8smQZMGlsQJXp6uafj8cMQDI8VZKeFeUgA4PVy\nUphL9HREMoPTWPU6NVQI74rdFuE53je1GP/0rSFSOE++9kJTp+JnF/eT/FwAtY0d4AIBKYTn9XFY\n/1Y1mh2uMLEDQiG61oi0656y2Tq6vXFbIfUXKdN77f7778djjz0GjUaD/fv344knnsDOnTuRlaUc\na75ScnJMPS+KgcWS3ic2JIJUsZXs7HuuxFZzuuBhZJn1ca/LygoNoBs3yhJ37bgSHnirWrAlxxhz\nrdjgdHC+Oe790s2CjT5eEBNLVpri+nSTDo5ONyyWdPgDgvdmsaRj5NAsfChLmwYAHkBmlhFaDYsO\nWaub9DQtvjG6QAqXGfRqdLt9sFjScaGxA59WN2HMiBxU19jA88ANQ7NxudkJP8cjIzMN3V4Oei0L\nt5dDS2coLPeNG3Ix5aZBeOlvXyLdbIAl14i/f/QVNrx1AoW5RqmAVu4Fmc0GWLJDv3dvsDi3M6Jg\nVaNVS78Ppd+Ly+PHiKLMhP8bTojoWK1WNDU1geM4sCwLjuPQ3NwMqzW+iy/HYrFIr2+//XZYrVac\nPXsWEydORGFhIerq6pCdLWxCNjQ04NZbb70iG202Z49NAZXtSkdLi/I3l2QjVWwlO/ueK7XV7RYe\njFpWFfe67q7QN/wckzbuWr3MufG6fYprLZZ0sIwKPgBZxvj3A4QwXV1TJzq7vWBVvPL6YHZbS0sn\n2jvd0GtZtLR0Il0XMujnD96CM5cd2PLhOdQ1tMNk0OBiYwduHJaF+799Awpy0uDscEEMnBm0Qrfu\nlpZOrP7rIQBAlkmLH04didc/+ArpWhYBv+BpXKxzoMPpQUF2Gi42O1F9LtQBwGLWw+cRxKKxuQNq\nPoCLDULIT6k3HQA0NHVAxYW8GEcwrFYXMb7B7uhGS0un4t/e3uFGS5sLpUOyrvrfMMOorurLekLC\nazk5OSgtLUVVVRUAoKqqCqWlpZJI9IamplD638mTJ1FXV4fhw4UMmZkzZ+L1118HANTW1uLYsWOY\nPHlyH34CghiY9Bhek4W/5JlmSjAqlRQSi6zjkSPuRQzO7/mBlhGcrMrzoayySCJTpkVvpUDmLRRZ\njNL1YjJBc1s38rLSMCjPFBXmM+jUUsissc2F/Ow0/POdxZgxcQhW/cftyM9Ok96n3emB1x9AfvD9\nLsrCa4UWo9TIVRzX0BX0sLRqBuNH5obZKV/n9XHY/M5pae+ptd0FRqXCmkVTYNCx8HiVuytwgQDW\nbjsOhlHhrhjzlPqThIXXli1bhsrKSqxduxZms1lKiV6wYAEWLlyIsrIyfP7553j66afhdDrB8zx2\n7NiB559/HpMnT8aqVatw4sQJMAwDjUaDlStXSt7Pww8/jMrKSkyfPh0Mw+C5556DyXT14TKCGOiI\nEzljPchF5Km88RqIipQOycKB6qaofm1KDM3vOeyTYdTiUvAbfqxNcZ2GhcfLIcALnRNEMcg266FV\nM+CDa8T2QZ7gvJwutz+mkKbphG4I4oC7aTcXSUWWYsKB+D4tDsETETPxbB0eFFmMmHbzIHzrxnyp\ndkcUO3uHG0Pz0/H4D8YiL9OAT443Yn1VtfTeooB+fro5rKuCy8PBoGNh0KmDyRPKxaEffFGH8/Ud\n+NH3x4QVCyeKhIlOcXExtmzZEnV8/fr10usJEybEzDqLrNuRk5aWhtWrV399IwmCABBq8WLqoYZD\n3hOsN6m38747CllmHcYM7znKUWTp+YGYadLizCVhdHSs0d+6YPbakbOtcLp8KB2aJdlbkJ2GTpcP\nKpUKOrWsa4JXSCKQNyOVY9Cp0enyoSW4eW9RECcxS27/sYbgvUIeiyXDIHkZ4qgH0YOxdbgxsihD\nErzIRq+nLznAsqqo9Gr5Wp0sY0/E3uFGtlmPM5ccyM8yYGKp8gC//oY6EhAEEQUXzODqqUVKb9qz\nyEnT/7/27j0mqjvtA/h3zgwzw224q4AiCxWC2K5YrH1Nx1XWRLqhLS1rXtbIZmussSb2DVYLtS1W\nW6Jgo70satKLiYlp/2mXtkqldX2NtaRVVxrr8rZV6h3UFQZ1QARmfu8f4znM4MxwcebMTPv9/AXD\neHj4ecLD73KeJwwL596nHI32eu0RPIUfEzmYaGI9xGoI02LAZkfj0QtIjDFiptMv2/szE5CdFgvA\ncbpOA+D4z/9RTq4leUg6cgme/3h5nzzT+f60Yw9HriwBYPDhWAz2SeobsMNuF7DcvO1SiWHoUuQ/\nDv2C6l3/clsnzuCcdJyOTF+8asXqbU34578uoru3H9HDHIX3p5A5vUZE6nnSnIFIo85jO2uZnBi8\nVawerb8WZg+7rCeLdarE4GmmIz9Ye+pCF/6YPxFap95DJX/IVD5OjA3HjKwkHGy+hIIZEwG4n8EA\njoRypbMHuxp/BOB+Pyvc6aDC6tLpmJg0uOTvfHxcTsB9AzZc7+6DzS5cyhoZPOx/uaut5pJ0nB90\n7XIkx/9tvgStpEH8MA8b+xNnOkR0l6jwMDw1J3PY2YZ0Z6bjy6KRc6enYuYwyU4mH0zQaTUey75k\nTXLMZASAjBTvzxJNn5KI7t4B/N85C+KiDR6fJ5IfEO2y9sGo17pNus7VIeQYZM5JR1le67crXVed\nq4Z7alPu3NNHng3Je2wGvdZlJiQ/R9R+rRvdvf1eG/35G5MOEY2Z/Ne2KQBPtgODy2sxXpaLxsWF\nK8kpM8Vz0VRgcGbzS9sNr6fx5KUzDYB1f5vp9nvLjeuAu5cKJzgtr4WFDS6vtZzthKTRuMQp13z7\n89xMl2s413ubN8OxP3Sm3XEyzhCmdanm3XmnTI+48++Gq8vmT0w6RDRmmakmZKSY8Jf5WQH5/nIy\nMUV6Xi7SaDTITY9HXLTBZQbhjvx1uxBeT3bJs5gpk2KVo9BDybPANKdZjbyX47zE53yQ4OQvnbgv\n1eRShNMUocd7FfPwxztLfrJ2p2KlefclwRCmVSpsG8Iklz0d5wQFQPUin864p0NEY2bU6/DyX/MD\n9v3l48mxw1TZXjR/Cm7dtg27eR4bZVB6BHlLOvKR76RY70msdvl/uRwlf/XpmXc1xJP3dLqst3Hu\nyk08aXat0A04TtqFDekIe7mjB+PjwvGnhycjM9WEv5eblROEhjDX5bXOG72IizYoy2wj3TPzB850\niChkRRp10Gklj4cIZBHGsBH1HJIkjfI+b0lHTnYPZCZ6vV5ibLjLMluYTuvyOeBYepM0GqXraHqy\n+32noUfSu3sHEBdtgPn3KdBoNC516fRDjkx33uhFptN+Fmc6RERjoNFosOyxqZg4zncPgyfGGHHV\ncgupXpLOjKxEvLN6HiJ1vjl2HBYmKfsx3r7vUJ5mLMY7BwnsQmDAZoflZh8ezh1cBhyu0oQ/MekQ\nUUgb7lj3aKUmRuFyZ4/Xsv8ajQbpyb6rvafXSbjZ56iWMFzvJGeeZiyGMC0EgI/+eQotZy2wC4E0\npwoPgTxIwKRDROTkyTm/Q+GsNFUfnpQPE6QmRo7q+3pKOsY7Bx32H7uovOZ8bJtHpomIgoRRP7rZ\nhi/IRwtGukyYN8Wxl+Su8RsAt6f0nDvAcqZDRPQbJh9pfnjq+BG9v9icgZTESKWL6lBDnzH608OT\nAQBp46Nw/oqVSYeI6LcsKjwM1lv9mDLR+8OrskijzqWEz1AJMUZIGg3sQmDt32bivjt131b993Sc\nv3zTbbFQtTDpEBEF2OtLZ0GjwYj3c4Yeux5Kp5UQbzLg2vVeJDlVtzZF6DEtI+GeYr1X3NMhIgow\nU6Qe0REjr1/nrQmebNydyteeKiYECpMOEVGIkUbQUiIlIRJR4WE+rQDuC1xeIyIKEbnpcfj3WcuI\n3vv4I7/DH/JSA9Y3xxPVks6ZM2dQWVmJrq4uxMbGoqamBunp6S7vOXz4MLZs2YKff/4ZZWVlqKio\nUL5WV1eHhoYGpV11eXk5zGYzAKCyshJNTU2Ii3N0BCwsLMSzzz6r1o9GRKSK/1n4+7tqt3kSjLMc\nQMWks27dOixatAhPPPEEPv30U1RVVWHXrl0u75k0aRKqq6uxb98+9PX1uXztgQcewJIlSxAeHo4f\nf/wRixcvxuHDh2E0Os6jL1u2DIsXL1brxyEiUp1OKyGAB898QpU9nY6ODrS0tKCoqAgAUFRUhJaW\nFnR2drq8b/LkycjJyYFOd3cuNJvNCA93bIxlZ2dDCIGuri7/B09ERD6jStJpb2/H+PHjodU6UrRW\nq8W4cePQ3t4+puvV19cjLS0NEyYMPhi1c+dOPPbYY1ixYgVaW1t9EjcREflWyB0kOHLkCN566y18\n8MEHymvl5eVISkqCJEmor6/H0qVLsX//fiXJjURCwtir1CYlRQ//piARKrEyTt8LlVhDJU4gdGIN\npjhVSTrJycm4cuUKbDYbtFotbDYbrl69iuTk5FFdp7m5GWvWrMG2bduQkZGhvD5+/GDpiOLiYmzc\nuBGXL19GamrqiK/d0WGFfYQbdM6SknxXadbfQiVWxul7oRJrqMQJhE6s/opTkjRj+mNdleW1hIQE\n5OTkYM+ePQCAPXv2ICcnB/Hx8SO+xokTJ1BeXo63334bubm5Ll+7cuWK8vHXX38NSZJcEhEREQUH\n1ZbXXn31VVRWVmLbtm0wmUyoqakBADzzzDN47rnncP/99+PYsWNYtWoVrFYrhBDYu3cvqqurYTab\nsX79evT29qKqqkq5Zm1tLbKzs1FRUYGOjg5oNBpERUVh+/btbg8jEBFRYGmEEKNfU/oVsli6x7S8\nlpAQhY4Oqx8i8r1QiZVx+l6oxBoqcQKhE6u/4pQkDeLiRt7lVMakQ0REqmHtNSIiUg2TDhERqYZJ\nh4iIVMOkQ0REqmHSISIi1TDpEBGRaph0iIhINUw6RESkGiYdIiJSDQuU3YORtOAOlIKCAuj1ehgM\nBgDA6tWrYTab8f3336Oqqgq3b99GamoqNm/ejISEBNXiqqmpQWNjIy5duoTPP/8cWVlZALyPZSDG\n2VOcnsYVQEDG1mKx4IUXXsD58+eh1+sxefJkbNiwAfHx8V7jCbZYs7OzkZWVBUly/B0s11UEgAMH\nDqC2thY2mw25ubnYuHGj0tDRX1asWIGLFy9CkiRERETglVdeQU5OTtDdp57iDLb71IWgMSsrKxP1\n9fVCCCHq6+tFWVlZgCMaNG/ePPHTTz+5vGaz2cT8+fPF0aNHhRBC1NXVicrKSlXjOnr0qGhra7sr\nPm9jGYhx9hSnu3EVInBja7FYxLfffqt8vmnTJvHiiy96jSfYYhVCiKysLGG1Wu/6N1arVcyePVuc\nOXNGCCHE2rVrxTvvvOP3WG/cuKF8/NVXX4ni4mIhRPDdp57iDLb71BmX18ZopC24g8nJkydhMBiQ\nn58PACgtLcW+fftUjSE/P/+uPkrexjJQ4+wuTm8CNbaxsbGYNWuW8vn06dPR1tbmNZ5gi9WbQ4cO\nYdq0acqMobS0FF988YU/wwQAREcPNj2zWq3QaDRBeZ+6i9ObYPgdwOW1MfLWgns0fYL8afXq1RBC\n4MEHH8SqVavQ3t6OlJQU5evx8fGw2+3KckCgeBtLIUTQjfPQcTWZTEExtna7HR9++CEKCgq8xhNs\nscrKyspgs9kwZ84crFy5Enq9/q5YU1JSxtzmfrReeuklfPPNNxBC4L333gva+3RonLJgvU850/mV\n2r17Nz777DN8/PHHEEJgw4YNgQ7pVyGYx/W1115DREQEFi9eHOhQhjU01oMHD+KTTz7B7t27cfr0\nadTV1QU4QqC6uhoHDx5EeXk5amtrAx2OR+7iDOb7lElnjJxbcAMYcwtuf5Hj0Ov1WLRoEY4fP47k\n5GSX5YzOzk5IkhTQWQ7gfSyDbZzdjav8eiDHtqamBufOncObb74JSZK8xhNssQKD4xoVFYWFCxd6\nHNe2tjbV/++Li4vx3XffYcKECUF9n8pxWiyWoL1PASadMfNFC25/6enpwc2bjp7oQgg0NDQgJycH\n06ZNQ29vL44dOwYA+Oijj1BYWBjIUAF4H8tgGmdP4wogoGO7ZcsWnDx5EnV1ddDr9cPGE2yxXr9+\nHb29vQCAgYEBNDY2KuNqNpvxww8/4OzZs0qsjz76qF9j7O7udlnCO3DgAGJiYoLuPvUUp8FgCMr7\nVMYmbvegtbUVlZWVuHHjhtKCOyMjI9Bh4cKFC1i5ciVsNhvsdjsyMzPx8ssvY9y4cTh+/DjWrVvn\nclwyMTFRtdhef/11fPnll7h27Rri4uIQGxuLvXv3eh3LQIyzuzh37NjhcVwBBGRsT506haKiIqSn\np8NoNAIAJk6ciLq6Oq/xBFOsS5cuRVVVFTQaDQYGBpCXl4e1a9ciMtLRlXL//v3YvHkz7HY7cnJy\nsGnTJkRERPgtzmvXrmHFihW4desWJElCTEwMKioqkJubG1T3qac4TSZT0N2nzph0iIhINVxeIyIi\n1TDpEBGRaph0iIhINUw6RESkGiYdIiJSDZMOUYC0tbUhLy9PeaCQ6LeASYdIRQUFBWhqagLgqCPW\n3Nys1Osi+i1g0iEiItUw6RCpZM2aNWhra8Py5cuRl5eHd999F9nZ2RgYGADgqLK8detWlJaWIi8v\nD8uXL4fFYsHzzz+PGTNmoKSkBBcvXlSu19raiqeffhoPPfQQFixYgIaGhkD9aEQjxqRDpJLNmzcj\nJSUFO3bsQHNzs9saYg0NDaitrcWhQ4dw/vx5lJaWoqSkBEeOHEFmZqZSfbmnpwdLlixBUVERmpqa\nsHXrVqxfvx6nT59W+8ciGhUmHaIg8tRTTyEtLQ3R0dGYM2cOJk2ahNmzZ0On06GwsBAtLS0AHK0A\nUlNTUVJSAp1Oh6lTp2LBggWqN+QiGi02cSMKIs6FFw0Gg8vnRqMRPT09AIBLly7hxIkTSgdIwFFO\n//HHH1cvWKIxYNIhCkHJycmYOXMmdu7cGehQiEaFy2tEKkpMTMSFCxfu+Tpz587F2bNnUV9fj/7+\nfvT39+PEiRNobW31QZRE/sOkQ6SiZcuWYfv27cjPz0djY+OYrxMVFYX3338fDQ0NMJvNeOSRR/DG\nG2+gr6/Ph9ES+R776RARkWo40yEiItUw6RARkWqYdIiISDVMOkREpBomHSIiUg2TDhERqYZJh4iI\nVMOkQ0REqmHSISIi1fw/K+4941vnvnUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BPtCE4KbeKU",
        "colab_type": "code",
        "outputId": "d227be2e-342d-41d6-95d3-ca79d10cf0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "quora_test_set = QuoraDataset(X_test,y_test)\n",
        "quora_test_dataloader = DataLoader(quora_test_set, batch_size=50, shuffle=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init QuoraDataset at: Thu Sep 19 13:23:51 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish init QuoraDataset at: Thu Sep 19 13:28:44 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc2C0PHfIn-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(quora_test_dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in quora_test_dataloader:\n",
        "      # print(data[0].shape)\n",
        "      inputs, labels =  data\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "      \n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the test sentences: %d %%' % (\n",
        "      100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my80GqhuIyws",
        "colab_type": "code",
        "outputId": "075efa9d-7ac0-489c-f259-ea6f74bdcf0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluate(quora_test_dataloader)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test sentences: 86 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLvvCPPadh4g",
        "colab_type": "code",
        "outputId": "989aaccb-72c8-4c98-e31c-a5979f70c07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del quora_test_set\n",
        "del quora_test_dataloader\n",
        "gc.collect()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw3WN7NeYgDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuoraNonStaticDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,X_train,y_train):\n",
        "    print(\"Init QuoraNonStaticDataset at: \"+str(ctime()))\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.embeddings = self.get_wiki_news_embeddings()\n",
        "    print(\"Finish init QuoraNonStaticDataset at: \"+str(ctime()))\n",
        "\n",
        "  def get_glove_embeddings(self):\n",
        "    return KeyedVectors.load_word2vec_format(root_path+data_path+\"gensim_glove_vectors.txt\", binary=False)\n",
        "\n",
        "  def get_wiki_news_embeddings(self):\n",
        "    return KeyedVectors.load_word2vec_format(root_path+data_path+'wiki-news-300d-1M/wiki-news-300d-1M.vec', binary=False)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    X = self.prepare_data(self.X_train.iloc[idx:idx+1,:])\n",
        "    return (X,self.y_train.iloc[idx])\n",
        "\n",
        "  def prepare_data(self,X_train):\n",
        "    chosen_question_length = 32\n",
        "\n",
        "    X_train_vectorized = self.vectorize(X_train,chosen_question_length)\n",
        "\n",
        "    return X_train_vectorized\n",
        "\n",
        "  def vectorize(self,X,chosen_question_length):\n",
        "    X_vectorized = np.empty((X.shape[0],chosen_question_length),dtype=np.long)\n",
        "    for i in range(X.shape[0]):\n",
        "      current_sentence = word_tokenize(X.iloc[i]['question_text'])\n",
        "      for j in range(chosen_question_length):\n",
        "        if j<len(current_sentence) and current_sentence[j] in self.embeddings:\n",
        "          X_vectorized[i,j] = self.embeddings.vocab[current_sentence[j]].index\n",
        "        else:\n",
        "          X_vectorized[i,j] = 0\n",
        "    return X_vectorized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivm8FLTIc4rk",
        "colab_type": "code",
        "outputId": "e7459156-2dac-4b38-a892-18ab06909393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "non_static_dataset = QuoraNonStaticDataset(X_train,y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init QuoraNonStaticDataset at: Thu Sep 19 15:40:55 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish init QuoraNonStaticDataset at: Thu Sep 19 15:45:49 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5eq6jdMIPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(non_static_dataset, shuffle=True, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8RRdxGSWSKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QIQRNN(nn.Module):\n",
        "  def __init__(self, output_size, hidden_dim, n_layers, drop_prob=0.5):\n",
        "    super(QIQRNN, self).__init__()\n",
        "    print(\"Init QIQRNN at: \"+str(ctime()))\n",
        "\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    # embedding and LSTM layers\n",
        "    self.embedding = nn.Embedding.from_pretrained(self.get_wiki_news_embeddings(), freeze=False)\n",
        "    self.lstm = nn.LSTM(300, hidden_dim, n_layers,dropout=drop_prob, batch_first=True)\n",
        "\n",
        "    # dropout layer\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    # linear and sigmoid layers\n",
        "    self.fc = nn.Linear(hidden_dim, 2)\n",
        "    self.sig = nn.Sigmoid()\n",
        "    print(\"Finished init QIQRNN at: \"+str(ctime()))\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    # embeddings and lstm_out\n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "    # stack up lstm outputs\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "    # dropout and fully-connected layer\n",
        "    out = self.dropout(lstm_out)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    # sigmoid function\n",
        "    sig_out = self.sig(out)\n",
        "\n",
        "    # reshape to be batch_size first\n",
        "    sig_out = sig_out.view(batch_size, -1)\n",
        "    sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "    # return last sigmoid output and hidden state\n",
        "    return sig_out, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "    # initialized to zero, for hidden state and cell state of LSTM\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    return hidden\n",
        "\n",
        "  def get_glove_embeddings(self):\n",
        "    embd = KeyedVectors.load_word2vec_format(root_path+data_path+\"gensim_glove_vectors.txt\", binary=False)\n",
        "    embd = torch.from_numpy(embd.vectors)\n",
        "    return embd\n",
        "  \n",
        "  def get_wiki_news_embeddings(self):\n",
        "    embd = KeyedVectors.load_word2vec_format(root_path+data_path+'wiki-news-300d-1M/wiki-news-300d-1M.vec', binary=False)\n",
        "    embd = torch.from_numpy(embd.vectors)\n",
        "    return embd\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCUvGijEeApd",
        "colab_type": "code",
        "outputId": "4ff92d94-cee4-467f-ef7b-ce4bdacbe83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "output_size = 1\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "net = QIQRNN(output_size, hidden_dim, n_layers).cuda()     # -- For GPU\n",
        "print(net)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init QIQRNN at: Thu Sep 19 15:46:04 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished init QIQRNN at: Thu Sep 19 15:50:54 2019\n",
            "QIQRNN(\n",
            "  (embedding): Embedding(999994, 300)\n",
            "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyPxVlkzbI-3",
        "colab_type": "code",
        "outputId": "999e68be-d0b4-4c59-ac17-7b9dfc68c557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBQpI0XYk6-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CVcqBBMHTIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training loop\n",
        "def train(net, trainloader, epochs=5):\n",
        "  counter = 0\n",
        "  batch_size = 50\n",
        "  print_every = 200\n",
        "  clip=5 # gradient clipping\n",
        "  loss_array = []\n",
        "  loss_time_array = []\n",
        "\n",
        "  # net.train()\n",
        "\n",
        "  for epoch in range(epochs):  \n",
        "    # torch.save(net.state_dict(), root_path+data_path+'rnn_model')\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        # print(\"Data Loading starts at: \"+str(ctime()))\n",
        "        # print(data[0].shape)\n",
        "        counter += 1\n",
        "        inputs, labels = data\n",
        "\n",
        "        # print(\"Finished fetching \"+str(len(inputs))+\" items at: \"+str(ctime()))\n",
        "\n",
        "        inputs = inputs.squeeze()\n",
        "        labels = labels.cuda() # -- For GPU\n",
        "\n",
        "        # forward + backward + optimize\n",
        "\n",
        "        if (inputs.shape[0]<batch_size):\n",
        "          continue\n",
        "\n",
        "        # print(inputs.shape)\n",
        "        # print(inputs[0])\n",
        "        inputs_long = torch.LongTensor(inputs).cuda() # -- For GPU\n",
        "\n",
        "        # print(\"Forward starts at: \"+str(ctime()))\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        output, h = net(inputs_long, h)\n",
        "\n",
        "        # print(\"Loss starts at: \"+str(ctime()))\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "        # print(\"Backward starts at: \"+str(ctime()))\n",
        "        loss.backward()\n",
        "\n",
        "        # print(\"Optimizer starts at: \"+str(ctime()))\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        # print(\"Optimizer ends at: \"+str(ctime()))\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i % 200 == 0) and (i > 0):    \n",
        "            print('%s: [%d, %5d] loss: %.3f' %\n",
        "                  (ctime().split()[3], epoch, i, running_loss / 200))\n",
        "\n",
        "            loss_array.append(running_loss / 200)\n",
        "            loss_time_array.append(ctime().split()[3])\n",
        "            running_loss = 0.0\n",
        "        # print(\"Step ends at: \"+str(ctime()+\"\\n\"))\n",
        "             \n",
        "  print('Finished Training')\n",
        "  return loss_array, loss_time_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt8Loxd7k9Is",
        "colab_type": "code",
        "outputId": "520942ea-27cf-456c-b8f7-de816d48c491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnn_loss_array, rnn_loss_time_array = train(net, train_loader)\n",
        "save_obj(net, 'net_lstm_rnn')\n",
        "save_obj(rnn_loss_array, 'rnn_loss_array')\n",
        "save_obj(rnn_loss_array, 'rnn_loss_time_array')\n",
        "# net = load_obj('net_lstm_rnn')\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16:00:56: [0,   200] loss: 0.269\n",
            "16:01:46: [0,   400] loss: 0.275\n",
            "16:02:37: [0,   600] loss: 0.270\n",
            "16:03:28: [0,   800] loss: 0.272\n",
            "16:04:19: [0,  1000] loss: 0.274\n",
            "16:05:10: [0,  1200] loss: 0.262\n",
            "16:06:01: [0,  1400] loss: 0.261\n",
            "16:06:52: [0,  1600] loss: 0.268\n",
            "16:07:42: [0,  1800] loss: 0.269\n",
            "16:08:33: [0,  2000] loss: 0.284\n",
            "16:09:24: [0,  2200] loss: 0.269\n",
            "16:10:15: [0,  2400] loss: 0.273\n",
            "16:11:53: [1,   200] loss: 0.202\n",
            "16:12:44: [1,   400] loss: 0.202\n",
            "16:13:35: [1,   600] loss: 0.213\n",
            "16:14:26: [1,   800] loss: 0.206\n",
            "16:15:17: [1,  1000] loss: 0.200\n",
            "16:16:08: [1,  1200] loss: 0.208\n",
            "16:16:59: [1,  1400] loss: 0.206\n",
            "16:17:50: [1,  1600] loss: 0.214\n",
            "16:18:41: [1,  1800] loss: 0.197\n",
            "16:19:32: [1,  2000] loss: 0.224\n",
            "16:20:22: [1,  2200] loss: 0.217\n",
            "16:21:13: [1,  2400] loss: 0.212\n",
            "16:22:52: [2,   200] loss: 0.163\n",
            "16:23:43: [2,   400] loss: 0.159\n",
            "16:24:33: [2,   600] loss: 0.155\n",
            "16:25:24: [2,   800] loss: 0.152\n",
            "16:26:15: [2,  1000] loss: 0.162\n",
            "16:27:06: [2,  1200] loss: 0.166\n",
            "16:27:57: [2,  1400] loss: 0.159\n",
            "16:28:48: [2,  1600] loss: 0.169\n",
            "16:29:39: [2,  1800] loss: 0.166\n",
            "16:30:30: [2,  2000] loss: 0.176\n",
            "16:31:21: [2,  2200] loss: 0.172\n",
            "16:32:11: [2,  2400] loss: 0.172\n",
            "16:33:49: [3,   200] loss: 0.127\n",
            "16:34:40: [3,   400] loss: 0.132\n",
            "16:35:31: [3,   600] loss: 0.128\n",
            "16:36:22: [3,   800] loss: 0.121\n",
            "16:37:13: [3,  1000] loss: 0.124\n",
            "16:38:03: [3,  1200] loss: 0.132\n",
            "16:38:54: [3,  1400] loss: 0.127\n",
            "16:39:45: [3,  1600] loss: 0.134\n",
            "16:40:36: [3,  1800] loss: 0.126\n",
            "16:41:27: [3,  2000] loss: 0.143\n",
            "16:42:18: [3,  2200] loss: 0.127\n",
            "16:43:09: [3,  2400] loss: 0.135\n",
            "16:44:47: [4,   200] loss: 0.092\n",
            "16:45:38: [4,   400] loss: 0.102\n",
            "16:46:29: [4,   600] loss: 0.098\n",
            "16:47:20: [4,   800] loss: 0.099\n",
            "16:48:11: [4,  1000] loss: 0.096\n",
            "16:49:02: [4,  1200] loss: 0.098\n",
            "16:49:53: [4,  1400] loss: 0.106\n",
            "16:50:44: [4,  1600] loss: 0.106\n",
            "16:51:35: [4,  1800] loss: 0.103\n",
            "16:52:26: [4,  2000] loss: 0.113\n",
            "16:53:17: [4,  2200] loss: 0.110\n",
            "16:54:08: [4,  2400] loss: 0.108\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-8rrbRLXwg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtEWGuei-Mrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "50a841af-ae11-4039-cead-88fae8263dc7"
      },
      "source": [
        "a = np.array(rnn_loss_array).reshape((len(rnn_loss_array),1))\n",
        "b = np.array([float(i) for i in range(len(rnn_loss_array))]).reshape((len(rnn_loss_array),1))\n",
        "print(b.shape)\n",
        "\n",
        "data = pd.DataFrame(np.concatenate((a,b),axis=1), columns = [\"loss\",\"time\"])\n",
        "# data.head()\n",
        "ax = sns.lineplot(x=\"time\", y=\"loss\", data=data)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAESCAYAAAAmOQivAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAqgvqmb8FFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46d24ba4-c93b-4356-a9bc-15239e518f37"
      },
      "source": [
        "del non_static_dataset\n",
        "del train_loader\n",
        "gc.collect()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6I4fLhrpoGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e4b85e2e-7c70-4de8-fc54-bd441bf1f55a"
      },
      "source": [
        "non_static_test_set = QuoraNonStaticDataset(X_test,y_test)\n",
        "test_loader = DataLoader(non_static_test_set, shuffle=True, batch_size=50)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init QuoraNonStaticDataset at: Thu Sep 19 17:03:45 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish init QuoraNonStaticDataset at: Thu Sep 19 17:08:39 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZiN0Hkf8VpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(quora_test_dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    h = net.init_hidden(50)\n",
        "    for data in quora_test_dataloader:\n",
        "      # print(data[0].shape)\n",
        "      inputs, labels =  data\n",
        "      inputs, labels =  inputs.squeeze(), labels.cuda()\n",
        "      if (inputs.shape[0]<50):\n",
        "        continue   \n",
        "      inputs_long = torch.LongTensor(inputs).cuda() # -- For GPU\n",
        "\n",
        "      outputs, h = net(inputs_long, h)\n",
        "      # print(outputs)\n",
        "      predicted = torch.round(outputs.squeeze()).long()\n",
        "      # _, predicted = torch.max(outputs.data, 1)\n",
        "      # print(predicted)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the test sentences: %d %%' % (\n",
        "      100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvYI0npQ8eqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c53e9b0d-b09e-4346-d9a0-a557295f762f"
      },
      "source": [
        "evaluate(test_loader)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test sentences: 87 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifeMS6FITS1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}